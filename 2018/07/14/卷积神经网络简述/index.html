<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>卷积神经网络简述 | 小竹&#39;s blog | 永远不要停止思考</title>

  
  <meta name="author" content="小竹">
  

  
  <meta name="description" content="小竹的博客">
  

  
  
  <meta name="keywords" content="Deep Learning">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="卷积神经网络简述"/>

  <meta property="og:site_name" content="小竹&#39;s blog"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="小竹&#39;s blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
<meta name="generator" content="Hexo 5.1.1"></head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">小竹&#39;s blog</a>
    </h1>
    <p class="site-description">永远不要停止思考</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/tags">Tags</a></li>
      
        <li><a href="/categories">Categories</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
        <li><a href="/link">Links</a></li>
      
        <li><a href="/about">About</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>卷积神经网络简述</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2018/07/14/卷积神经网络简述/" rel="bookmark">
        <time class="entry-date published" datetime="2018-07-14T16:00:32.000Z">
          2018-07-14
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>前言： 我太菜了… 本来想着写个小例子，结果写到一半发现自己其实根本不会，我还是撸C++去吧。</p>
<p>卷积神经网络(Convolutional Neural Network)是一种前馈神经网络。它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色的表现。</p>
<p>卷积神经网络由一个或多个卷积层和顶端的全连通层组成，同时也包含关联权重和池化层。这一结构可以使得卷积神经网络能够利用输入数据的二维结构。与其他深度学习结构相比，卷积神经网络在图像和声音上能够给出更好的结果，这一模型也可以用反向传播算法进行训练。相比较于其他神经网络、前馈神经网络，卷积神经网络需要考虑的参数更少，使之成为一种颇具吸引力的深度学习结构。</p>
<a id="more"></a>

<h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>卷积神经网络中每层卷积层由若干卷积单元构成。每个卷积单元的参数都可以由反向传播算法来调整。卷积运算的目的是提取输入的不同特征，第一层卷积可能只提取非常小的特征，更多层的网络只能从低级特征中提取更复杂的特征。</p>
<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>运行时激活神经网络中某一部分神经元，将激活信息向后传入下一层神经网络。神经网络之所以能解决非线性问题，如语音和图像，本质上就是激活函数加入了非线性的因素，弥补了线性模型的表达力，把“激活的神经元的特征”通过函数保留并映射到下一层。</p>
<p>因为神经网络的数学基础是处处可微，所以选取的激活函数要能保证数据输入与输出也是可微的，介绍四种函数：</p>
<ul>
<li>sigmoid</li>
</ul>
<img src="/2018/07/14/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0/sigmoid.svg" class="" title="sigmoid">

<img src="/2018/07/14/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0/sigmoid.png" class="" title="sigmoid">

<p>sigmoid函数是传统神经网络中最常用的激活函数之一，它的优点在于，它的输出映射在(0, 1)内，单调连续，非常适合作为输出层，并且求导比较容易，缺点也比较明显，因为软饱和性，一旦落入饱和区，f’(x)就会变得接近0，很容易产生阶梯消失。</p>
<ul>
<li>tanh</li>
</ul>
<img src="/2018/07/14/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0/tanh.jpg" class="">

<img src="/2018/07/14/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0/TanhReal.gif" class="">

<p>tanh函数也具有软饱和性，因为它的输出以0为中心，收敛速度比sigmoid要快，但是仍然无法解决梯度消失问题。</p>
<ul>
<li>relu</li>
</ul>
<img src="/2018/07/14/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0/relu.svg" class="">

<img src="/2018/07/14/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0/relu.png" class="">

<p>relu是目前最受欢迎的激活函数，softplus可以看做是relu的平滑版本。使用线性整流（Rectified Linear Units, ReLU）f(x)=max(0,x)作为这一层神经的激励函数（Activation function）。它可以增强判定函数和整个神经网络的非线性特性，而本身并不会改变卷积层。</p>
<ul>
<li>dropout</li>
</ul>
<p>一个神经元将以概率决定是否要被抑制，被抑制的神经元会被暂时认为不属于网络，但是它的权重将会被保留。</p>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>池化是卷积神经网络中另外一个非常重要的概念。它实际上是形式的降采样。有多种不同形式的非线性池化函数，而其中“最大池化”是最为常见的。它是将输入的图像划分为若干个矩形区域，对每个子区域输出最大值。直觉上，这种机制能够有效地原因在于，在发现一个特征之后，它的精确位置远不及它和其他特征的相对位置的关系重要。池化层会不断地减小数据的空间大小，因此参数的数量和计算量也会下降，这在一定程度上也控制了过拟合。通常来说，CNN的卷积层之间都会周期性地插入池化层。</p>
<p>池化层通常会分别作用于每个输入的特征并减小其大小。目前最常用形式的池化层是每隔2个元素从图像划分出2x2的区块，然后对每个区块中的4个数取最大值。这将会减少75%的数据量。</p>
<p>除了最大池化之外，池化层也可以使用其他池化函数，例如“平均池化”甚至“L2-范数池化”等。过去，平均池化的使用曾经较为广泛，但是最近由于最大池化在实践中的表现更好，平均池化已经不太常用。</p>
<p>由于池化层过快地减少了数据的大小，目前文献中的趋势是使用较小的池化滤镜，甚至不再使用池化层。</p>
<h3 id="损失函数层"><a href="#损失函数层" class="headerlink" title="损失函数层"></a>损失函数层</h3><p>损失函数层用于决定训练过程如何来“惩罚”网络的预测结果和真实结果之间的差异，它通常是网络的最后一层。各种不同的损失函数适用于不同类型的任务。例如，Softmax交叉熵损失函数常常被用于在K个类别中选出一个，而Sigmoid交叉熵损失函数常常用于多个独立的二分类问题。欧几里德损失函数常常用于结果取值范围为任意实数的问题。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/Deep-Learning/">Deep Learning</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/Deep-Learning/">Deep Learning</a>
    </span>
    

    </div>

    
  </div>
</article>

  

	<section id="comment" class="comment">
		<div id="vcomments"></div>
	</section>
	<!-- LeanCloud -->
	<script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.10.0/dist/av-min.js"></script>
	<!-- Valine -->
	<script src="//unpkg.com/valine/dist/Valine.min.js"></script>
	<script>
		new Valine({
			el: '#vcomments',
			appId: 'jwJxh95ly6NdjTRluyKYXm6G-gzGzoHsz',
			appKey: 'lagqr7doy2slbm7oAMGoogpg'
		})
	</script>






    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    </br>
    
    &copy; 2020 小竹
    
  </p>
</footer>
    
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-129024325-1', 'auto');
    ga('send', 'pageview');

</script>

  </div>
</div>
</body>
</html>