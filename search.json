[{"title":"如何给Arch打一个包","date":"2021-03-04T11:23:42.000Z","url":"/2021/03/04/package-manager-for-arch/","tags":[["Linux","/tags/Linux/"]],"categories":[[" ",""]],"content":"Arch 使用的是 pacman 包管理器，包格式是 tar.zst。Arch 提供了一些工具用于创建 tar.zst 包，首先需要安装 base-devel 包和 dev-tools 包。 Arch 的打包流程是这样的，要先写一个 PKGBUILD 文件，这个文件描述了构建一个包所需的全部信息，如从哪里下载源码，依赖有哪些，构建的版本是多少，如何进行构建等。 PKGBUILD一个基本的 PKGBUILD 格式如下： 以 dtkcore 为例，整个配置文件十分清晰明了，一看就知道构建工具是如何一步步制作出一个包的。 将配置文件保存到目录里，以 PKGBUILD 命名，然后执行 makepkg。 makepkg 是用于执行 PKGBUILD 文件的工具，它根据文件中的描述，进行包的构建。 如何提交一个包到 aur当你希望自己打的包可以被别人使用的时候，一般都会请求上传到官方仓库，但是进入官方仓库的流程异常繁琐，而且对贡献者的要求会比较高。Arch 提供了一个用户仓库，供用户自由分享配置文件，只需要下载配置文件，在本机打包就可以了。 根据 aur 的 贡献指南，我们可以很轻松的上传自己的配置文件，并借用yay等aur工具自动下载和构建软件包。 用户可以通过 Arch User Repository 分享 PKGBUILD。AUR 中不包含任何二进制包，仅包含用户上传的 PKGBUILD，供其他用户下载使用。所有软件包都是非官方的，使用风险自担。 提交aur之前，需要先了解一下 aur 的一些要求，Rules of submission 提供了一些规则，只要我们按照规则来，就可以上传和维护我们自己的包。 首先需要去 aur官网 注册一个账号，并上传自己的 ssh key 我们通过克隆一个新的仓库来作为上传的方式。 以dtkcore为例，克隆的时候把pkgname改成dtkcore。 如果是第一次创建，会提示你克隆的一个空仓库。 把 PKGBUILD 文件复制到克隆的目录，然后执行 makepkg --printsrcinfo &gt; .SRCINFO 创建一个软件包信息，将 .SRCINFO 和 PKGBUILD 文件都添加到 git 中，然后提交 commit 信息，推送到服务器。 注意： 如果您忘记在首次提交中包含 .SRCINFO，您可以使用 rebasing with –root 或是 filtering the tree 使得 AUR 接受您的第一次推送 提示： 为了保持工作目录和提交尽可能的干净，可以创建 gitignore 文件来排除所有文件，然后再按需添加文件。 参考资料：  "},{"title":"timemachine","date":"2021-02-27T11:35:29.000Z","url":"/2021/02/27/timemachine/","categories":[[" ",""]],"content":"接着上篇的 samba，我给家里配置了 samba 服务器，为家里提供共享存储服务。 我在我笔记本上安装了黑苹果，所以也想顺便试试传说中的 Time Machine 自动备份，说不定还能整一套给 deepin 使用呢。 话不多说开干。 安装 avahiAvahi 是一种免费的零配置网络实现，包括用于多播 DNS / DNS-SD服务发现的系统。它可以帮助我们广播 samba 服务器，这样网络内其他机器就可以查找到 samba 服务器了。 在 arch 上安装 avahi。 我们并不需要配置什么，直接开启服务就行了。 配置 samba我们还需要稍微配置一下 samba 服务，专门开辟一个用于备份的目录。 修改 /etc/samba/smb.conf，添加一个 timemachine 的条目。 还需要设置 smb 协议的版本和开启苹果的支持，在配置文件中查找或者添加新的，注意，这里的配置文件必须是在上面条目的上方，我推荐是放在 dns proxy 的下方。 然后我们重启一下 samba 和 avahi的服务。 此时 TimeMachine 和 Finder 都会显示 samba 服务器了。 开启 time machine打开设置，进入时间机器，打开选择一个硬盘。 选择共享的timemachine，点击使用硬盘，然后会弹出来认证的对话框，输入用户名和密码即可。 配置就算完成了，只需要等待自动备份，或者选择下面的在菜单栏中显示时间机器，在菜单栏里选择立即备份。"},{"title":"samba","date":"2021-02-27T10:42:53.000Z","url":"/2021/02/27/samba/","tags":[["Linux","/tags/Linux/"]],"categories":[[" ",""]],"content":"samba 是一个linux下开源的SMB/CIFS协议的免费软件，最初 SMB 协议是 Microsoft 开发的网络通讯协议，后来微软又把 SMB 改名为 CIFS（Common Internet File System），即公共 Internet 文件系统，并且加入了许多新的功能，这样一来，使得Samba具有了更强大的功能。 samba目前最大的作用是文件共享，服务器只需要提供账号和密码，就可以由 samba 客户端访问，并挂载到本地系统上。 我在家用了一个 macmini 当做家庭 nas，并且使用 archlinux 当做服务器系统，我在上面部署了 samba 服务，seafile 服务，nextcloud 服务，plex 服务，arai2c 下载机。 除了 samba 服务，其他服务都是运行在 docker 中，所以 samba 服务需要我手动配置。 安装archlinux 安装 samba 服务很简单，只需要使用 pacman 安装 samba 包即可。 安装完成以后我们就可以创建用户和配置共享目录了。 配置由于 samba 不提供配置文件，所以我们要从网上下载基本的 配置文件。 创建用户我们需要先在系统创建对应的用户，以我的用户名 lxz 为例。 禁用用户登录由于该用户只是为了权限相关的操作，所以我并没有计划使用该账户，如果需要在系统中使用该账户，则不需要进行接下来的禁用操作。 禁用本地登录 禁用ssh登录 修改 /etc/ssh/sshd_config ，修改 AllowUsers。 创建 samba 用户我们需要区分的是，尽管 samba 的用户和 Linux 系统本身的用户是同一个，但是密码则是分开存放的，我们需要使用 samba 提供的命令修改用户的密码。 修改密码则不使用 -a 参数： 测试到此，我们已经完成了基本的 samba 配置，配置文件里默认开启了用户的家目录访问，所以我们使用 smb 客户端进行登录的时候，可以直接访问家目录。 开启服务 使用 smbclient 可以验证本机服务。 添加其他的共享目录除了用户家目录，我们还可以共享特定的目录。 例如我创建一个 data 目录，允许任何人只读访问。 修改 /etc/samba/smb.conf 文件，在末尾处添加配置。 然后重启 samba 服务，使用 smbclient 验证。 "},{"title":"2020 Review","date":"2021-02-26T22:51:45.000Z","url":"/2021/02/26/2020review/","categories":[[" ",""]],"content":"2020拖了这么久才更新博客，想必大家都在 2020 年过的挺不好的，年初武汉的疫情打了全国一个措不及防，甚至已经一整年了，全球疫情还是十分紧张。截止到 2021 年 2 月 26 日，全球每日新增仍然有30 多万，而且全球累计死亡已有 250 万人之多。 疫情生命是如此的脆弱。有些时候和朋友们一起吃饭，会说起一月份时大家是如何 逃离 武汉的，在家隔离又多了哪些事情，我们活着是多么的不容易。虽然人类已经可以生产 5 纳米的芯片了，但是就如同我们对这个宇宙的认知一样，几百亿光年外任我们看，可太阳系内有什么我们都不知道，甚至在地球上还有很多我们未知的东西。 计划失误2020 年我的计划几乎没有一件事是完成的，我计划应该一整年掌握 TypeScript 和 web 开发，并开发自己的blog系统，但是方案被我推到重来了三次，我就没耐心继续开发了，只完成了基本的 md 文件编译和服务器渲染就暂停了。计划阅读 《1984》 、 《TensorFlow》 和 《TypeScript实战》 ，然而只有 《TypeScript实战》阅读完了，剩余两本书我则是只看了一丢丢，看来只能放到 2021 年读完了。 她在 2019Review 的文章里，我提到了我遇到了生命中的那个她，而 2020 年，我和她 结婚 啦。 在家隔离的日子里，有她陪伴着我，虽然老家的人都挺敌视从武汉回来的我，但是大门一关我谁也看不到，眼不见心不烦，在家一块搓麻将挺好的，还一起练 (zao) 习 (ta)了厨艺，朋友圈做饭比赛第一名。 学习虽然我读书拉后了，但是我的英语 坚持 了下来，我使用多邻国进行英语和日语的学习，已经坚持快6个月了，需要继续加油努力，争取早日把学校里拉下的英语 补 回来。 工作2020 年最大的收益可能是创建了 deepin-git 的仓库，提供了 dde 所有组件在 arch 上的git版，并且还成功申请到了 archlinuxcn 的贡献者。 文章2020 年一共水了18篇文章。 研究了 vscode 的插件，开发了一个 qmake 的插件原型，可以打开 dtk 等 qt pro 的项目，利用 bear 拦截 make 的编译信息，生成 ccls 需要的数据库，这样就可以为项目提供自动补全和语法检查等功能了。 写了一些关于远程开发的文章，也是利用 vscode 的远程功能，不得不说 vscode 真的可以说是宇宙第一编辑器了，让老牌的 vim 和 emacs 知道了什么叫易用性的力量。 展望2021 年，不能松懈，今年要继续努力学习，努力提升自己。 在 2021 年里，我将会负责 deepin 的社区，由于前两年公司需要快速扩张，导致忽略了社区，现在我们的首要任务就是恢复社区，并让社区良性的自由发展，社区是我们的根本。 挖了很多坑，今年争取都填一下。 其他又搬家了，找了一个一室一厅，开启了二人的小日子，过了年以后把狗子也带来了，现在天天早上起来打狗，晚上回来打狗。 我又给 肝疼3 氪了一个月卡，这次只忘了一天没登录，不然 30 块大洋又要白花了。 祝大家幸福安康，新年快乐！(^▽^)"},{"title":"ccls","date":"2020-12-23T16:27:39.000Z","url":"/2020/12/23/ccls/","tags":[["Linux","/tags/Linux/"],["vim","/tags/vim/"]],"categories":[["Linux","/categories/Linux/"]],"content":"LSP(Language Server Protocol) 语言服务协议，此协议定义了在编辑器或IDE与语言服务器之间使用的协议，该语言服务器提供了例如自动补全，转到定义，查找所有引用等的功能；语言服务器索引格式的目标是支持在开发工具中进行丰富的代码导航或者一个无需本地源码副本的WebUI。 而ccls就是为c/c++开发的一个的lsp服务，可以为vim、emacs和vscode等工具提供自动补全，定义跳转等功能。 根据本文的指导，你可以将vim配置成一个不错的c++开发工具。 准备工作由于公司部分项目并不是CMake开发的，所以vscode无法完成胜任开发工作，所以我开始使用vim。系统我使用的是ArchLinux,我会尽量使用仓库中的包，而不是通过pip等工具安装组件。 安装安装neovim、ccls和bear,bear目前只在archlinuxcn仓库，需要注意。 下载SpaceVim，由于我使用的是neovim,所以下载配置时选择了neovim. 创建自己的配置文件目录 配置首先要先创建基本的SpaceVim配置文件，配置文件参考了。 整个配置都在~/.SpaceVim.d目录下。 在.SpaceVim.d目录下创建init.toml 创建plugin目录，新建两个文件。coc.nvim defx.nvim 创建autoload目录，新建myspacevim.vim 创建coc的默认配置文件，原本coc的配置文件应该是在~/.SpaceVim下的，但是在autoload的配置文件中，设置了coc_config_home，修改为.SpaceVim.d下，方便控制。 使用启动nvim的时候，就会开始安装所有的插件，等带最终配置完成。 现在进去一个C++的项目里，由于ccls需要知道项目都使用了哪些文件，所以需要我们为它创建配置文件，如果项目是CMake的，可以直接执行命令生成compile_commands.json文件，如果不是CMake的项目，则需要使用bear对Makefile进行编译，bear会拦截编译信息，最终生成compile_commands.json。 CMake： Makefile： 等文件生成完毕后，使用ln命令将文件软链回项目根目录。 此时已经配置完成一半了，我们还需要在根目录创建.ccls文件，并写入一下配置： 此时ccls就可以读取compile_commands.json的信息，为我们提供自动补全等功能了。 问题如果出现了找不到vimproc动态库在nvim中执行 :VimProcInstall进行重新编译。"},{"title":"Qt多线程","date":"2020-11-17T15:53:37.000Z","url":"/2020/11/17/qt-multi-thread/","categories":[[" ",""]],"content":"类型注册 Qt 有三种多线程的方式，分别是继承 QThread、使用 QObject 的 moveToThread 函数和 Qtconcurrent 协程。 在很多文章中，大家都推荐继承 QThread 类，并重写 run 方法，在 run 中使用耗时操作代码。这种方式让我们觉得 QThread 是线程的实体。创建一个 QThread 对象就认为是开辟了一个新的线程。这种讨巧的方法似乎能帮助我们快速入门，但是只要深度了解多线程编程就会发现，这样子做会使代码脱离我们的控制，代码越写越复杂。最典型的问题就是明明将代码放入了新线程，但是仍然在旧线程中运行。 我们应该把耗时代码放在哪里？ 暂时不考虑多线程的情况，我们一般都会将耗时代码封装到一个类中。在考虑多线程的情况下，难道我们要将代码剥离出来放到某个地方吗？其实不用这么麻烦。在 qt4 时代，我们需要使用继承 QThread 的方法，这样会破坏我们原有的代码结构，并且 run 方法只能运行一段代码，如果我们有成千上万个函数，我们总不能封装如此多的 QThread。 所以在 Qt5 中，Qt 库完善了线程的亲和性以及信号槽机制，我们有了更为优雅的使用线程的方式，即 QObject::moveToThread()。这也是官方推荐的做法。 我们准备两个类来介绍和解释一下工作流程。 controller.hpp handler.hpp 在 main.cpp 中初始化对象，并连接信号和槽。 看一下执行结果: 可以看出来两个函数获取到的QThread对象并不是同一个了。使用 movetothread 将一个对象移动到新的线程，并通过信号调用目标函数，从而达到在新线程执行的目的。 使用这种方式，我们可以方便的通过操作QThread对象来控制线程的执行，例如设置线程的优先级别，暂停线程或者恢复线程。并且这种方式比继承QThread可以更加直观的感受到，QThread只是一个线程的管理类，而不是线程实体，如果采用继承的方式，则会认为QThread就是线程实体，从而造成一定的认知混乱。 还有一种多线程的方式，这种方案更加的灵活，不需要我们new新的QThread对象，是一个较高层次的API封装。QtConCurrent可根据计算机的 CPU 核数，自动调整运行的线程数目。 在使用Qtconcurrent之前需要添加对应的Qt模块concurrent。 在使用的时候，我们需要添加一个QFutureWatcher对象，用来控制和执行一个QFuture对象，并且通过finished信号接收QFuture对象的执行结果。 以上就是一个简单的例子，不难发现，Qt为我们提供了相当不错的解决方案，这种形式比较类似于QDbus对象使用QDbusPendingCallWatcher来异步获取结果的方式，使用起来非常容易上手。在使用多线程的时候，我们需要注意一些事情：互斥与同步同步，类型注册，在线程中开辟线程。 在多线程开发中，我们需要注意的地方就有点多了，最重要的就是线程同步，我们需要使用一些手段，让不同线程中的函数可以正确的访问的数据。 互斥：一个公共资源同一时刻只能被一个进程或线程使用，多个进程或线程不能同时使用公共资源。 同步：两个或两个以上的进程或线程在运行过程中协同步调，按预定的先后次序运行。 解决方法：互斥锁，条件变量，读写锁，自旋锁，信号量（互斥与同步）。 在Qt编程中，我们可以利用Qt的信号与槽机制实现两个对象的通信，无论两个对象是否在同一个线程，但是我们传递参数需要注册给Qt的元对象系统，否则Qt将无法完成数据传递。 在Qt中注册自定义类型有两种方式，一种是qRegisterMetaType()函数和Q_DECLARE_METATYPE(Type)宏。 这两种注册方式有不同的作用。使用qRegisterMetaType()函数可以让自定义类型在Qt的信号槽中传递，而Q_DECLARE_METATYPE(Type)宏则是可以让注册的自定义类型使用QVariant进行包装。 在多线程开发中我们还需要注意，Qt存在半自动内存管理，这个内存管理方式会影响着我们使用多线程开发。我们在创建新的QObject对象时，如果制定了parent，则该对象将与父对象进行线程绑定。如果两个对象在不同的线程中，Qt会警告我们父对象的线程和当前对象的线程不是同一个，他们将无法使用Qt的connect函数进行消息传递。"},{"title":"deepin-wine中文乱码","date":"2020-09-17T16:32:12.000Z","url":"/2020/09/17/deepin-wine-chinese-problem/","tags":[["Linux","/tags/Linux/"]],"categories":[["技术","/categories/%E6%8A%80%E6%9C%AF/"]],"content":"众所周知，使用wine来运行windows下的一些软件是linux用户的常用操作，deepin为社区贡献了好几款中国用户必备的软件，例如QQ、微信、企业微信，以此来让更多的人无痛的切换到linux来。近年来value也一直在linux上布局，先后推出了steam主机和proton,前者是基于kvm和steam大屏幕模式的系统，而proton则是wine的分支，value提供了几组补丁用来提高性能和与Windows游戏的兼容性。 Arch上有非常方便的aur仓库，有很多用户都自己提交一些软件到aur上面，就有几个维护者将deepin打包的deepin wine和对应的软件包移植到Arch上面来，已经是很多人在Arch上面运行QQ和微信的首选方案。 但是使用的过程中我遇到了以下几个问题： 输入框中文乱码 在DDE桌面使用kwin的情况下最小化会卡死 KDE桌面环境无法使用deepin wine的程序 第二个问题比较特殊，因为dde在deepin和uos下运行的是fork版本的kwin,而Arch上运行的则是原版的kwin,一些操作代码并不具备，所以会出现一些奇葩的状况。 第三个问题则是xsettings的原因，在移植者的仓库有对应的issue讨论 《KDE环境完全无法使用wine-tim》 第一个问题解决起来也比较简单，是因为缺少了宋体文件，从而无法正确的渲染中文字体。而比较奇葩的是，把方块复制再粘贴，就可以正确的渲染了。 解决的方法也很简单，把windows的的字体复制过来就可以了。由于版权的问题，没办法直接提供文件，需要各位自己复制了。 引用资料 "},{"title":"使用rEFInd来安全启动系统","date":"2020-09-08T19:54:26.000Z","url":"/2020/09/08/use-refind-to-boot-system/","tags":[["Linux","/tags/Linux/"]],"categories":[["技术","/categories/%E6%8A%80%E6%9C%AF/"]],"content":"今年的七夕，我老婆给我买了一台surface laptop 2代，8G内存 + 256G存储版本，我也成功的用上了田牌的机器。 2020/09/17更新： 不知道为啥，反正是开了对内核签名以后，哪怕是BIOS关闭了安全启动，仍然出现mkinitcpio会卡在autodetect上，无奈全部都删掉重来了，没有弄签名，希望各位看到本文章以后解决了这个问题能回复一下，谢谢。 surface默认是开启了安全启动(Microsoft签名)和bitlocker来保障设备和系统安全，我作为一个linux系统的开发者，当然是需要在surface上装一个linux了，但是前两年zccrs已经踩过坑了，linux不识别surface键盘，同样的触摸、网卡、声卡等设备也工作的不是很正常，本来以为我要开启远程开发的生活了，还特意写了一篇《使用VSCode远程开发DDE》，来给公司里有同样烦恼的人，让他们也感受一下远程开发的魅力。 苍天不负有心人，我成功的！ 我成功的使用上了ArchLinux,并且工作的十分良好。这多亏了github上的一个组织linux-surface，有这么一些人，他们付出劳动来让手里的surface设备也用上linux,并且要和普通的x86兼容机一样工作，感谢他们的付出，也让我吃上了螃蟹，安装的过程我就不在这里详细说了，其实非常简单。 首先因为surface只有一个usb口，而键盘并不能工作，所以需要一个usb的扩展器。先按fn+f6进bios关闭掉安全启动，修改引导顺序为usb优先，之后就是正常的安装系统，但是不需要安装仓库里的内核，我们需要安装linux-surface提供的仓库里的内核。 这些都是非常正常的步骤，linux-surface提供了自己的仓库和内核，我们正常使用即可。 这里开始就是我研究了半天的内容， 开启安全模式! 首先我看了一下arch wiki上有关于安全启动的内容，写的挺详细的，就是看不懂。讲了各种的知识点，各种签名的方式，但是真正到我开始用的时候，我是一直失败的，失败的方式我就不说了，直接说我如何成功的。 首先我放弃了grub,一个原因是grub的安全启动我一直没有尝试成功，另外一个是我只有一个系统，没必要用grub。我换成了rEFInd来作为我的bootloader，首先安装rEFInd的引导。 来解释一下上面两条明令。第一个是安装必要的软件包，refind是bootloader本体，shim-signed是aur里面的用于安全启动的包，shim提供了一种并行的安全启动验证功能，我们使用它来启动refind的efi,再通过refind的efi启动内核，达到终极套娃启动。sbsigntools是用于给文件签名的工具，我们安装完refind以后，refind会帮助我们生成一份默认的key,我们需要使用这个key来为内核进行签名。 在执行第二条明令以后，会有几次询问，都选择Y回车就行。 然后使用sbsigntools来对内核进行签名。 准备工作已经进行一半了，我们只需要写一下refind的配置文件，就可以启动了。 refind的配置文件有两个地方，一个是boot分区下面的refind_linux.conf，还有一个是在efi分区里的EFI/refind/refind.conf，我们需要修改的是后者。 默认配置文件都是注释的，其实我们全部删了就可以了，有需要修改的地方去看原始文件或者文档就行了。 添加一个menuentry，就可以启动系统了。 我用的是btrfs文件系统，所以配置文件有点罗嗦。解释一下上面的内容。 also_scan_dirs是指定扫描某个目录，因为我是btrfs文件系统，必须使用这个才能让refind扫描到内核文件，否则会无法启动。 dont_scan_dirs是跳过指定的目录，因为refind默认是会扫描所有的efi文件，我们自己提供了emnuentry,所以不需要让它扫描了。 dont_scan_files是跳过指定的文件，这里是防止其他目录出现对应的efi也被扫描到。 scan_all_linux_kernels是扫描所有linux内核，这样所有的内核就会出现在启动列表里，我们同样也是不需要的。 menuentry里面需要修改的地方有，volume是分区的partuuid,我因为这个uuid就测试了好几次，最后才反应过来不是filesystem uuid,要求的是partition uuid. 所有遇到ArchFS的地方都是不需要的，因为btrfs支持字卷，我的系统是在一个叫ArchFS的卷里面的，如果不是btrfs的文件系统，这个是不需要的，同样options里的rootflags选项也是不需要的，这是传递给内核的参数，让内核可以正确的加载根分区。 这样就算完工了，重启系统，然后进bios里把安全启动改成Microsoft &amp; 3rd party CA，然后重新启动。 当第一次加载rEFInd的时候，因为我们的证书是才生成的，主板并没有存储对应的签名，rEFInd会启动mmx64.efi来让我们加载证书，证书的位置在/etc/refind.d/keys下，选择refind_local.cer导入，然后选择重启，重新进入系统就可以了。 导入证书这部分我其实不太确定，因为我除了使用shim方案，我还测试了preloader方案，那个方案会一开始就启动一个MOK的工具进行证书导入，我记不太清shim到底需不需要手动导入了，如果出现了，那就导入一下就行了，没出现的话就能正常的看到引导界面和进入系统了。 还有一个后续的动作需要处理，就是内核升级以后，我们需要对内核重新签名，否则会被bios拒绝启动。 编辑/etc/pacman.d/hooks/99-secureboot.hook,并写入以下配置： 享受安全启动吧～ "},{"title":"deepin git version","date":"2020-09-06T12:51:08.000Z","url":"/2020/09/06/deepin-git-version/","tags":[["Linux","/tags/Linux/"]],"categories":[["技术","/categories/%E6%8A%80%E6%9C%AF/"]],"content":"This repository only provides the git version of deepin. You can replace the deepin group in the community by installing the deepin-git group. The PKGBUILD for all packages are there , Each branch saves the corresponding software. Before adding this repository, you should first add the key used to sign the packages in it. You can do this by running the following commands: It is recommended that you now fingerprint it by running and in a final step, you have to locally sign the key to trust it via More infos on this process can be found at . You can now add the repository by editing /etc/pacman.conf and adding at the end of the file. See  for details. to install deepin git version: If you don’t want to use the repository anymore, you can uninstall deepin git, or install the deepin group in Community. to install deepin group for community. "},{"title":"使用VSCode远程开发DDE","date":"2020-09-03T11:14:38.000Z","url":"/2020/09/03/use-vscode-to-remotely-develop-dde/","tags":[["Linux","/tags/Linux/"],["VS Code","/tags/VS-Code/"],["Windows","/tags/Windows/"]],"categories":[["Linux","/categories/Linux/"],["技术","/categories/Linux/%E6%8A%80%E6%9C%AF/"]],"content":"本文将介绍如何使用VSCode的远程开发套件连接到Deepin主机，进行DDE和其他软件的开发与调试. 介绍Visual Studio Code（简称VS Code）是一个由微软开发，同时支持Windows 、 Linux和macOS等操作系统的免费代码编辑器，它支持测试，并内置了Git 版本控制功能，同时也具有开发环境功能，例如代码补全（类似于 IntelliSense）、代码片段和代码重构等。该编辑器支持用户个性化配置，例如改变主题颜色、键盘快捷方式等各种属性和参数，同时还在编辑器中内置了扩展程序管理的功能。 在VSCode出来之前，Sublime曾经是前端开发者必备的软件，它使用python作为插件运行环境，并且也拥有不少的插件，但是很遗憾的是插件不能更改界面元素，可玩性不是很高。 再后来Atom作为GitHub的顶梁柱出现了，它基于使用Chromium和Node.js的跨平台应用框架Electron（最初名为Atom Shell），并使用CoffeeScript和Less撰写，并且支持js开发的插件，一时间拥有非常多的用户，并且从Sublime那里拉拢了非常多的前端开发者。 但是一切都在VSCode面世以后变了。VSCode同样也是基于Chromim和Electron开发，并且支持TypeScript开发插件，而且启动速度比Atom快很多，而且作为微软面向开源社区的主力产品，它和TypeScript一样，吸收了社区的很多意见和贡献，使得软件越来越好用。在语言支持方面，对 C#、JavaScript、和 TypeScript 等编程语言的原生支持最为完善。 安装VS Code官网提供的有vscode的安装包，windows用户下载stable版本的exe(System Installer)。 System Installer可以自动下载对应语言的环境包，推荐安装此版本。 安装完成后就可以安装插件了。 安装插件插件系统是一个编辑器的左膀右臂，emacs和vim作为终端下开发经常使用的编辑器，就拥有非常丰富的插件，几乎每个大佬使用的emacs和vim都不能互换使用。 dde的项目几乎都是cmake的项目，所以需要安装cmake插件和c++的插件，安装了这两个插件以后。vscode打开项目工程就会自动解析CMakeLists.txt，并且开启vscode的快速调试功能，还可以开始构建项目和调试项目了。 安装CMake、CMake Tools这两个插件就可以开发了。 安装C/C++和C++ Intellisense这两个插件可以对项目中的c++代码进行智能感知和代码补全，推荐安装。 安装Remote - SSH插件，可以让vscode通过ssh连接到目标机器，打开远程机器的目录和文件，并且在该模式下，部分插件可以自动切换成本地/远程模式，这样就可以在本机直接开发，但是操作的内容都是远程环境的。 安装完Remote - SSH插件以后，vscode的左下角就会有一个绿色的按钮，可以用来切换模式。 配置远程环境因为是要在Windows上进行远程开发，如果是直接在UOS或者Deepin上开发DDE，这一部分是可以不用看的，上面的插件安装完成以后就可以开发项目了。 点击左下角的绿色按钮，在弹出的面板选择Remote-SSH: Connect to Host。 会继续弹出一个面板，用来选择配置ssh的连接。 选择Add New SSH Host添加一个服务器。 输入ssh的命令，例如 ssh &#108;&#120;&#x7a;&#x40;&#49;&#x30;&#46;&#50;&#48;&#46;&#x33;&#x32;&#x2e;&#x35;&#52;。 然后选择一个保存配置的位置，一般默认选择用户家目录的.ssh目录即可。然后就提示添加成功，此时可以点击Connect按钮进行连接。 输入密码 登录以后会打开一个新的窗口，并提示正在连接。连接成功以后可以在左下角看到机器的信息。 然后打开命令面板，选择在SSH中安装本地扩展。 在打开的列表选择全选，然后安装。 等待全部安装成功。 开发和调试功能介绍CMake插件提供了编译、运行和调试的功能和命令，可以点击下方面板中的select target，选择要运行的目标程序，选择切换编译模式，可以选择Debug或者Release。还可以选择使用哪个编译器进行构建。 设置启动参数如果程序启动不需要提供参数，则可以直接点击下方面板的Debug按钮，或者打开命令面板选择CMake Debug Target，如果没有选择过Target，则会询问一次设置Target。 点击左侧的调试按钮，选择添加配置。 在弹出的面板选择GDB 此时vscode会创建出一个json文件，并生成了默认的配置文件。 我们需要进行一些调整，以便使用该配置文件进行调试。 program字段是程序二进制文件的位置，一般情况下我们是要手动写好路径，但是如果项目的二进制特别多，更换配置文件就会非常麻烦，而且配置文件里写死路径也不是很方便，我查阅了CMake插件的文档，发现CMake插件提供了两个很重要的变量，可以让我们方便的查找到路径。 CMake插件提供了launchTargetPath的变量，它对应的是CMake插件选择的默认target，启动调试之前需要我们先选择好Target。 CMake插件还提供了launchTargetDirectory变量，用于获取程序启动所在的目录，一般需要我们指定到本次调试所需的环境变量中。 然后我们就可以添加启动参数了。args字段保存了程序启动会传递的参数列表，例如这里会给fuse传递-d和/tmp/x。 完整的配置如下： gdb调试此时我们就可以先通过CMake插件构建整个项目，再切换到运行面板，启动调试。 点击下方面板的Build按钮，构建项目。 再点击左侧的gdb fuse(deepin-turbo)按钮，因为配置文件里面我们起的名字是gdb fuse。我们在main函数添加一个断点，用来测试gdb是否工作正常。 一切都工作正常，在调试控制台可以使用-exec作为前缀来执行gdb的命令。 调试图形程序调试图形程序稍微有一些麻烦，因为是远程开发，图形程序又只能工作在目标机器，这里提供两个可行的方案。 synergy之类的键盘鼠标共享软件 在windows安装xserver 第一种方案是通过共享本机的键盘鼠标到远程机器，这样就可以在远程环境上面进行直接操作，好处是除了调试，也可以同时操作远程机器进行使用。 第二种方案是利用X11协议的网络透明，既图形程序和显示服务不一定在同一台机器上运行，我们只需要在Windows安装XServer程序，就可以让远程机器上的程序的画面显示到当前机器，并且可以操作。但是此方案有缺点，虽然设计上这种分离结构设计的很巧妙，但是因为远程OpenGL调用并不支持，所以图形无法调用3D程序渲染，并且和远程机器沟通需要大量的带宽，所以用起来体验并不好。 为了使用这两种方案，我们都需要在调试的launch.json中添加一个环境变量。 在运行面板点击齿轮按钮，可以编辑当前方案。 在打开的json文件中，找到environment字段，添加DISPLAY环境变量。 这样程序启动就有DISPLAY环境变量，我们就可以让程序在目标机器的屏幕上运行了。 还有一种自动化测试的方案，该方案是我个人认为所有开发都应该掌握的，通过自动化测试，我们就可以完全使用远程开发来完成开发任务，调试的时候只需要等待自动测试结果返回即可，设想一下，某个模块需要点击很多地方才可以重现一个问题，我们只需要设置好断点，让程序自动开始执行所有函数，并在最终出现问题的地方停下，我们就可以开始手动单步跟踪问题，完全不需要使用鼠标人工点击。（然而理想很美好，现实很残酷，我个人目前都没有掌握自动化测试的方式，现在也是只能通过鼠标点点点来重现问题。"},{"title":"在ArchLinux上开发startdde","date":"2020-08-06T16:14:26.000Z","url":"/2020/08/06/develop-startdde-on-archlinux/","tags":[["dde","/tags/dde/"],["go","/tags/go/"]],"categories":[["Linux","/categories/Linux/"]],"content":"dde 后端使用 go 作为主要的开发语言，使用 dbus 提供接口，主要使用 gsettings 来保存配置。 所以在进行后端开发前需要对以上内容有基本的了解，这里假定本文档的阅读者熟悉 dbus 和 gsettings，并有一定的开发经验。 安装依赖虽然本项目是go语言开发的，但是我们并没有直接使用go的mod作为依赖管理方案，而是走系统包管理器的方式，所以要先安装startdde的编译依赖。 这些包会被安装到系统的/usr/share/gocode目录下。还需要手动go get一个依赖到本地的GOPATH中。 设置GOPATH为了方便以后的开发，可以将GOPATH环境变量定义到~/.xprofile等文件中，或者shell的配置文件。例如我使用的zsh： 设置项目目录go要求项目目录必须在GOPATH中，所以要将startdde放到GOPATH的pkg.deepin.io/dde/目录下，但是GOPATH每次进入不方便，可以采用软链的形式将startdde的目录链接到GOPATH下。 这样就可以在一个方便的目录进行开发了。 vscode开发工具我个人推荐使用vscode当作开发工具，打开vscode安装go的插件，打开startdde目录，vscode会提示安装一些go的工具，选择全部安装即可。"},{"title":"use github action to check dde-launcher","date":"2020-07-27T18:14:21.000Z","url":"/2020/07/27/use-github-action-to-check-dde-launcher/","tags":[["Linux","/tags/Linux/"]],"categories":[["技术","/categories/%E6%8A%80%E6%9C%AF/"]],"content":"本来打算7月份给dde添加github action验证，但是被各种事情耽误了，然后发现麒麟居然抢在我前面部署了全套的github action，这不能忍，赶紧把dde的github action也提上日程。并且打算听肥肥猫大佬的话，在aur给dde弄一套commit构建包，这样就可以在arch上使用比testing仓库更testing的dde了！ github actions是github官方出的持续集成功能，以前大家在github上的项目都使用的第三方的Travis CI或者自建jenkins构建，但是github被微软收购以后，微软为了表现出给社区和用户的诚意，将大量github的付费功能免费公开给开发者使用，希望能将github打造成开发者中心，于是在2019年微软推出了免费的github actions，每个项目都可以免费使用官方提供的持续集成和持续部署功能，这对第三方业务无疑是个巨大的打击，虽然Travis CI和jenkins等方式仍然有一定的市场，但是对于中小项目的开源项目，使用官方提供的功能无疑是方便的。 github actions的配置十分简单，只需要几个简单的步骤就可以实现构建、执行和测试代码。并且可以使用Linux、Windows和MacOS环境，机器性能也十分强劲，编译速度非常的快。 这是给dde-launcher的一份基础配置，需要将配置文件放在.github/workflows/目录下，以build.yaml文件名保存。 介绍一下配置文件吧，name是设置ci的名字，github允许有多个ci存在，可以做不同的事情，例如部署三个ci，一个做语法检查，一个做静态检查，一个做编译检查。name就是用来在界面上显示的。on是设置ci对哪些事件感兴趣，在这里我设置了push和pull_request，当发生push和pull request时，这个ci就会被启动，执行接下来的jobs的内容。jobs里是可以设置多个任务的，同样name字段也是用来展示本次动作的名称。runs-on是设置该job工作的环境，ubuntu-latest是linux环境，container是指使用哪个docker容器，github actions是可以使用docker的，也可以将自己的ci配置共享给其他人使用。run就是执行命令了，在配置文件中我手动运行了刷新仓库和编译项目所需的命令。job的steps可以理解成shell中一次动作的执行，uses是使用其他人封装好的命令，run则是执行本地命令。 可以看出github actions的配置是十分简单的，并且构建速度也非常的快，并且构建环境是使用的arch linux环境，为什么要选择arch作为ci的基础构建环境呢，原因当然不是因为和肥肥猫有py交易，arch上的dde更新速度很快，并且很多用户都使用arch+dde的方式使用linux，deepin自己维护的发行版因为基础仓库更新较慢，不适合一些用户，所以为了能让dde被更多的人接受和使用，在arch上及时更新dde是十分有必要的。所以才选择actions的环境为arch linux。"},{"title":"使用perf工具分析程序性能","date":"2020-07-21T09:15:11.000Z","url":"/2020/07/21/use-perf-to-analytics-program/","tags":[["Linux","/tags/Linux/"]],"categories":[["优化","/categories/%E4%BC%98%E5%8C%96/"]],"content":"最近在对DDE进行性能优化，所以补习了一下linux下的各种分析工具的使用方法。 这张图是来自Brendan Gregg大佬提供的linux分析工具的应用场景，可以看出几乎包含了系统每个地方应该用什么工具去分析。 Linux Perf Tool允许系统进行分析为了能够正常分析，首先需要打开系统的调试功能，允许我们去对其他进程进行访问。 SysCtl较新的Linux内核具有sysfs可调参数/proc/sys/kernel/perf_event_paranoid，该参数允许用户调整perf_events非root用户的可用功能，数量越大则越安全（相应地提供较少的功能）： 默认值是不允许获取任何信息，所以我们需要修改为1或者0，允许我们访问CPU的事件信息。 临时修改 执行命令向内核接口直接写入值。 永久修改 使用sysctl来配置其值，创建/etc/sysctl.d/50_perf_event_paranoid.conf文件，并写入kernel.perf_event_paranoid=1，执行sysctl -p来刷新系统配置。 perf 采样 性能优化相关的三种类型的工具，一种是sampling类型的，即采样，这种工具就是不停“询问”程序在做什么，perf在我们使用的这种模式下就是 sampling模式，如果是追踪某些event，就工作在trace模式，实际上就是第二种类型的工具，这种工具主要依靠事件或者hook，程序在运行的过程中不停主动告诉工具它自己在做什么，比如 strace；第三种是 instrument 类型的，这种主要就是依赖编译器进行插桩，精确知道代码行级别的执行情况（参考gcc instrumentation ）。 by hualet on deepin 15.7 我们通过perf record命令才对程序进行采样记录。 命令介绍： perf可以直接启动一个程序进行分析，也可以使用-p参数指定一个pid进行采样。 查看 perf 的采样结果当我们通过perf record完成采样以后，会在执行目录生成perf.data文件，此时我们就可以使用perf report命令对data文件进行数据分析了。 perf report会自动打开当前目录下的perf.data文件，当然也可以在最后指定perf.data文件的路径。 perf report会根据–call-graph参数来生成不同的图，使用dwarf参数时会以函数调用栈的顺序来显示，使用这种方式可以方便的看出哪个函数执行的时间比较长，因为每次采样都能落到该函数上，也就意味着函数执行的时间非常长，再通过调用栈的深度来分析函数执行期间都在做什么事情。 hotspot火焰图在命令行下查看函数调用不是特别方便，所以就有图形化的工具用来方便的查看perf工具的生成结果，其中使用比较友好的是kde开发的hotspot工具，该工具可以直接打开perf.data文件，并生成对应的火焰图，火焰图是函数调用的另一种表现形式，火焰越高，也就意味着调用栈越深，火焰越广，也就意味着函数执行的时间很长。"},{"title":"CTest & QTest/GTest","date":"2020-06-16T15:11:40.000Z","url":"/2020/06/16/CTest%20&%20QTEST/","tags":[["Qt","/tags/Qt/"],["C++","/tags/C/"],["CMake","/tags/CMake/"],["GTest","/tags/GTest/"],["CTest","/tags/CTest/"]],"categories":[["unit test","/categories/unit-test/"]],"content":"本文会介绍一下QTest和GTest的一些功能和区别。 单元测试ctestctest是CMake提供的运行单元测试的工具，在使用CMakeLists.txt文件编译工程的时候，CTest会自动configure、build、test和展现测试结果。 ctest有两个模式： 模式一：使用CMake configure和build工程，在CMakeLists.txt，使用特殊的命令创建tests。使用CTest来执行那些测试。 模式二：使用CTest来执行一个script，这个script的语法必须和CMakeLists.txt相同。 使用方法： 在CMakeLists.txt使用include(CTest)和include(Dart)来导入CTest模块和开启ctest。使用add_test()来添加一个测试程序，测试程序是一个普通的二进制，只不过内部运行的是qtest或者gtest编写的测试用例。 qt qtestqtest是Qt提供的单元测试框架，Qt Test是用于对基于Qt的应用程序和库进行单元测试的框架。Qt Test提供了单元测试框架中常见的所有功能以及用于测试图形用户界面的扩展。 Qt测试旨在简化基于Qt的应用程序和库的单元测试的编写： 特征 描述 轻量 Qt Test大约有6000行代码和60个导出符号组成 自成体系 Qt Test仅需要Qt Core模块中的几个符号即可进行非GUI测试 快速测试 Qt Test不需要特殊的测试运行程序，没有特殊的测试注册 数据驱动测试 可以使用不同的数据进行多次的测试 基本的GUI测试 Qt Test提供了用于鼠标和键盘的模拟功能 标杆管理 Qt Test支持基准测试，并提供多个测量后端 IDE友好 Qt Test输出可以由Qt Creator、Visual Studio等IDE解释的消息 线程安全 错误报告是线程安全和原子的 类型安全 模板的广泛使用可以防止隐式类型转换引起的错误 易于扩展 可以将自定义类型轻松添加到测试数据和测试输出中 断言QVERIFY() 用于验证数据是否正确。 循环QFETCH_GLOBAL() 该宏从全局数据表中的一行中获取类型类型为name的变量。 名称和类型必须与全局数据表中的列匹配。 这是断言，如果断言失败，则测试将中止。 QFETCH() 宏会在堆栈上创建一个类型为name的本地变量。 名称和类型必须与测试数据表中的列匹配。 这是断言，如果断言失败，则测试将中止。 比较QCOMPARE宏用于判断两个值是否相等，如果实际值和预期值匹配，将会继续运行，否则将失败记录在测试日至中，并且测试将被终止，不会尝试任何后续操作。 添加数据通过在包含_data()的函数中调用QTest::addColumn和QTest::newRow向测试用例增加数据，并通过QFETCH宏在测试用例中访问数据。 创建测试要创建测试，需要派生自QObject，并添加一个或多个专用槽函数。每个专用槽函数都是测试中的一个测试功能且必须为private。函数命名方法以casen_函数名或者以test结尾的方式。 使用QTest::qExec()可用于执行测试对象中的所有测试功能。 此外，还可以定义不用于测试功能的专用槽函数。如果存在，它们将由测试框架执行，并用于初始化和清除整个测试或当前的测试功能。 initTestCase() 将在第一个测试功能执行之前被调用 initTestCase_data() 将被调用以创建全局测试数据表 cleanupTestCase() 在最后一个测试函数执行后被调用 init() 将在每个测试功能执行之前被调用 cleanup() 将在每个测试函数之后调用 使用initTestCase()准备测试。每次测试都应使系统处于可用状态，因此可以重复运行。清理操作应在cleanupTestCase()中处理，因此即使测试失败也可以运行清理操作。 使用init()创建测试功能。每个测试功能都应使系统保持可用状态，以便可以重复运行。清理操作应在cleanup()中，即使测试功能失败并提前退出，清理动作也可以运行。 另外，可以使用RAII,并在析构函数中调用清除操作，以确保他们在测试函数返回且对象移出作用域时发生。 如果initTestCase()失败，将不执行任何测试功能。如果init()失败，则不执行以下测试功能，测试将继续进行下一个测试功能。 最后，如果测试类具有静态且公共的void initMain()方法，则在实例化QApplication对象之前，由QTEST_MAIN宏调用该方法。例如，这允许设置应用程序的属性，例如Qt::AA_DisableHighDpiScaling。这是在Qt5.14添加的。 使用CMake和CTest构建测试项目CMake还有其他优点。例如，几乎可以毫不费力地使用CDash将测试运行的结果发布到Web服务器上。 CTest可以扩展到非常不同的单元测试框架，并且可以与QTest一起使用。 google testgoogle test(gtest)是google公司推出的c++单元测试框架，基于xUnit架构，并且支持Linux、Windows和mac，并且支持任何类型的测试和模拟，而不仅仅是单元测试。 基本概念当使用gtest时，通过编写断言来检查条件是否为真。断言的结果可能是成功、非致命失败或者致命失败。如果发生致命故障，将终止当前功能，否则将继续运行。 一个测试套件包含一个或者多个测试。当测试套件中的多个测试需要共享通用对象和子例程时，可以将他们放入一个测试桶中。 一个测试程序可以包含多个测试套件。 断言gtest断言类似于函数调用的宏，可以通过断言其行为来测试类或者函数。断言失败时，gtest会输出断言的源文件和行号位置以及失败消息。还可以提供自定义失败消息，该消息将会附加到gtest的消息之后。 断言成对出现，测试相同的事物，但是对当前函数有不同的影响。ASSERT_版本失败时会产生致命错误，并终止当前功能。EXPECT_会产生非致命错误，不会导致当前测试失败。通常EXPECT_是首选，因为他们允许在测试中报告多个鼓掌，但是如果在断言失败时继续运行将没有意义时应当使用ASSERT_。 由于ASSERT_*失败会从当前函数立即返回，可能会跳过其后的清理代码，导致内存泄漏。 基本断言基本断言可以进行基本的真/假条件测试 致命断言 非致命断言 验证 ASSERT_TRUE(condition); EXPECT_TRUE(condition); condition是真的 ASSERT_FALSE(condition); EXPECT_FLASE(condition); condition是假的 请记住，当它们失败时，将导致ASSERT_致命故障并从当前函数返回，而当它们发生EXPECT_非致命故障时，将允许该函数继续运行。无论哪种情况，断言失败都意味着其包含测试失败。 字符串比较该组中的断言比较两个C字符串。如果要比较两个string对象，请改用EXPECT_EQ，EXPECT_NE等。 致命断言 非致命断言 验证 ASSERT_STREQ(str1,str2); EXPECT_STREQ(str1,str2); 这两个C字符串的内容相同 ASSERT_STRNE(str1,str2); EXPECT_STRNE(str1,str2); 两个C字符串的内容不同 ASSERT_STRCASEEQ(str1,str2); EXPECT_STRCASEEQ(str1,str2); 两个C字符串的内容相同，忽略大小写 ASSERT_STRCASENE(str1,str2); EXPECT_STRCASENE(str1,str2); 两个C字符串的内容不同，忽略大小写 注意，断言名称中的“ CASE”表示忽略大小写。一个NULL 指针和一个空字符串被认为是不同的。 STREQ并STRNE接受宽C字符串（wchar_t*）。如果两个宽字符串的比较失败，则它们的值将打印为UTF-8窄字符串。 简单测试创建测试： 使用TEST()宏定义和命名测试功能。这些是没有返回值的普通C++函数。 在此函数，要与包含的所有有效C++语句一起使用各种gtest断言来检查。 测试结果由断言确定，如果测试中的任何声明失败（致命或非致命），或者测试崩溃，整个测试都会失败，否则测试应当成功。 TEST()函数第一个参数是测试套件的名称，第二个参数是测试套件内的测试名称。这两个名称都必须是有效的C++标识符，并且不应包含任何下划线。来自不同测试套件的测试可以具有相同的名称。 参考资料：qtest gtest"},{"title":"CPP项目的一些坑","date":"2020-06-15T11:11:40.000Z","url":"/2020/06/15/CPP%E9%A1%B9%E7%9B%AE%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/","tags":[["C++","/tags/C/"]],"categories":[[" ",""]],"content":"本篇文章记录这几年项目中C++的一些问题和优化方法。需要注意的是，代码优化没有一本万利的方法，只能见招拆招，而且还要避免过早优化等问题，代码优化一定是要中后期才可以，而且不要为了优化而优化。 const和const &amp;在接收一个返回值或者声明局部只读变量时没有使用const修饰。const的目的不仅仅是为了只读，更多的是编译器可以在此处提供优化。 在这两行例子中，react和scale都在当前函数内没有任何修改，而且不应该修改，需要添加const来修饰只读，并且QRect应该使用&amp;来减少内存复制带来的额外影响。 类型强转在部分代码中，经常能看到C风格的代码强转，应当根据具体情况使用static_cast、dynamic_cast和reinterpret_cast。 static_cast是使用的比较多的cast，经常用于派生类和基类之间转换。dynamic_cast也用于派生类和基类的转换，如果类型T是指针类型，若转换失败，则返回T类型的空指针，如果时T是引用类型，则会抛出异常，返回std::bad_cast。reinterpret_cast并不会做实际的转换，只会在编译时进行检查，如果不能进行cast转换，则编译报错。 过多的嵌套过多的嵌套会严重影响代码阅读，经常出现只有if通过才会进入执行的情况，这种情况应该修改为不通过就不要继续执行，或者安排合理的if将条件限制在之前。 这里的代码其实是可以优化的，我们可以通过三元表达式获取某个QDBusPendingCall，这样就可以使用一个QDBusPendingCallWatcher对象，然后将原本的lambda内容提取到其他函数内，在新的lambda中同样使用三元表达式运行对应的函数，这样拆分代码的好处是，阅读代码时的顺序会和执行顺序一致，分支判断对机器和人类都不是太友好，特别是判断体内有很长的代码段，找到else段是一件不容易的事情，通过降低if else块来提高代码可读性。同时应提取相同动作的代码到公共区域，以免将来修改时发现没有将所有的地方都做修改。 循环避免使用数组的方式来访问元素，使用迭代器的方式统一循环方式。 我注意到有些情况下，有人在for循环内直接定义静态变量，这种方式使用的时候需要注意，静态变量将会永远存在，但是大部分for循环内需要保存的数据都是成员变量，否则内存空间将永远不会释放，对内存有浪费。 而且经常遇到的问题就是foreach宏和for混用，在语法上就没有统一使用。 我推荐的方式是for+迭代器的方式，如果是简单遍历，使用原生的foreach语法即可。 内存泄漏经常遇到使用容器将指针保存下来的场景，但是当对象被析构或者容器被清空的时候，有时候会忘记删除内部的对象，或者删除了不该删除的对象。对数据的处理应该保持RAII原则，避免直接使用裸指针，而是通过智能指针将指针保存起来，当最后一个对象不再持有智能指针对象时，智能指针会删除持有的对象，完成内存释放。 智能指针的类型 智能指针包含有三种：独占指针unique_ptr、共享指针shared_ptr和弱引用指针week_ptr。 独占指针独占指针std::unique_ptr可以避免对象被转移到其他对象中，如果某个对象持有unique_ptr，则该ptr不允许转移给其他对象，但是可以使用std::move来转移控制权，注意这和普通的转移不一样，unique_ptr禁止的是拷贝，但是没有禁止移动，我们可以转移控制转，unique_ptr保证的是只有一个智能指针持有对象。 共享指针共享指针std::shared_ptr顾名思义是用作共享的，和独占指针不同的是，它支持复制，内部通过引用计数来维持对象的生命周期，当没有任何一个对象持有共享指针时，也就意味着没有任何一个对象可以访问到内部对象了，就可以安全的删除对象，释放内存。 弱引用指针弱引用指针std::week_ptr是为了避免两个共享指针相互持有导致引用计数永远不会归零，导致内存永远不释放而提出的解决方案，具体就是弱引用指针不会导致引用计数增加，但是week_ptr同样不支持复制，必须转换为共享指针std::shared_ptr。 优化判断条件对于常数的判断，尽量使用宏或者定义静态常量来避免直接使用数字或者字符判断。 排序发现很多人在需要排序的时候总是使用冒泡算法，我介绍几个比较方便的排序方法。 使用std::sortC++标准库提供了std::sort方法来方便的排序，它有三个参数，第一个参数是容器的begin迭代器，第二个参数是end迭代器，第三个参数接收一个返回值为bool类型的函数，该函数用于实现手动控制排序的判断。 我们可以提供一个lambda表达式来方便的控制排序，或者提供一个函数指针。 这种排序方式是直接对原始容器进行操作的，如果不希望数据成为脏数据，应该先复制一份。 使用容器使用容器的方式比较麻烦一些，我们需要对象自己支持大小比较，或者顺序是外部某个列表列表控制的。 我们可以使用map将内部数据和标记数据建立映射关系，再通过外部的list或者其他方式，从map中将数据读出来，添加到新的列表容器中，从而完成排序。 "},{"title":"使用inquirer提供交互式git commit","date":"2020-06-15T10:36:19.000Z","url":"/2020/06/15/%E4%BD%BF%E7%94%A8inquirer%E6%8F%90%E4%BE%9B%E4%BA%A4%E4%BA%92%E5%BC%8Fgit-commit/","tags":[["Linux","/tags/Linux/"]],"categories":[[" ",""]],"content":"公司计划规范所有commit提交，开发部门综合出来了一份模板。 python inquirer之前在掘金上看到有人在使用交互式的commit来规范commit信息，觉得用起来挺不错的，刚好符合本次公司的要求，不过原项目是nodejs的，项目里肯定不能让每个开发都安装一个node,所以就找一下代替品，然后就发现了python-inquirer。 使用起来也非常的方便，通过inquirer.Text、inquirer.List、inquirer.Checkbox就可以创建相应的交互，并把组合好的列表交给inquirer.prompt处理，返回一个对象，内部包含了所有做出的选择。 Text List CheckBox 公司的模板 修改git editor将上面的内容保存到/usr/bin/git-inquirer。 当我们执行git inquirer的时候就能看到交互，当操作完成后可以看到git log中message已经是按模板填充了。"},{"title":"vue-router路由复用后页面没有刷新","date":"2020-06-01T10:35:41.000Z","url":"/2020/06/01/vue-router%E8%B7%AF%E7%94%B1%E5%A4%8D%E7%94%A8%E5%90%8E%E9%A1%B5%E9%9D%A2%E6%B2%A1%E6%9C%89%E5%88%B7%E6%96%B0/","tags":[["Web","/tags/Web/"]],"categories":[[" ",""]],"content":"vue-router提供了页面路由功能，可以用来构建单页面应用，在使用vue-router的动态路由匹配的时候，遇到了url变化了，但是页面却没有任何动静的问题，记录一下。 动态路由匹配url变化了，但是组件没有变化是因为vue进行了组件复用，因为两个路由都渲染同个组件，比起销毁再创建，复用则显得更加高效。不过，这也意味着组件的生命周期钩子不会再被调用。所以我们需要手动进行数据刷新。 我们可以简单的使用watch来监听当前的路由变化，从而实现数据刷新。 也可以使用2.2中新加的beforeRouteUpdate路由守卫： 以上就是vue3中使用vue-router-next来处理动态路由变化导致页面不刷新的方法。"},{"title":"vue3升级遇到的坑","date":"2020-05-31T21:11:43.000Z","url":"/2020/05/31/vue3-upgrade/","tags":[["web","/tags/web/"]],"categories":[[" ",""]],"content":"最近一直忙工作上的事，对提高自身能力的事有点落下了，趁着今天把之前思考的一些问题都给解决了，也顺手给自己的VueBlog把vue和webpack都升级到最新的beta版本，然后遇到了很多坑，今天就把坑都记录一下，免的以后忘了。 VueBlog目前使用的是webpack5 + vue3 + vue-router-next + typescript构建，目的在于替换当前的hexo站点，同样也是一个静态博客生成器，不过和hexo的定位不同，我使用的是单页面设计，而不是给每个页面生成对应的html文件，所以对SEO不友好，以后再想办法吧。 升级Vue3首先使用vue add vue-next来升级vue到beta版本，执行以后vue会对代码进行一次转换，将旧版本的一些api转换为新版本。 App例如将main.ts中创建App对象的代码转换为新的，在vue2中，我们通过new Vue()来创建app对象，并调用$mount函数挂在元素。 在vue3中，主体思想都尽量通过函数来进行了，因为可以通过函数的参数和返回值进行类型推导。在vue3中，创建app对象通过createApp函数来进行，再通过mount函数挂载dom元素。 Vur Router如果使用的有vue-router之类的插件，使用方法也有一些变化，router也需要通过对应的create函数创建。首先需要先升级vue-router，vue-router的下一个版本叫vue-router-next。在vue-router中，创建router对象的函数从VueRouter函数改为createRouter。 在vue3中则需要使用新的函数返回： 内容也改了一部分，可以访问github仓库来看文档。 composition APIcomposition api是vue3提出的核心功能，其核心目的是通过将分散在各处的数据都整合到一个setup函数中进行初始化，并依赖vue的响应式数据改变来完成功能实现。 在RFC中就有composition api的动机。 更好的逻辑复用与代码组织 随着功能的增长，复杂组件的代码变得越来越难以阅读和理解。这种情况在开发人员阅读他人编写的代码时尤为常见。根本原因是 Vue 现有的 API 迫使我们通过选项组织代码，但是有的时候通过逻辑关系组织代码更有意义。 目前缺少一种简洁且低成本的机制来提取和重用多个组件之间的逻辑。更好的类型推导另一个来自大型项目开发者的常见需求是更好的 TypeScript 支持。Vue 当前的 API 在集成 TypeScript 时遇到了不小的麻烦，其主要原因是 Vue 依靠一个简单的 this 上下文来暴露 property，我们现在使用 this 的方式是比较微妙的。（比如 methods 选项下的函数的 this 是指向组件实例的，而不是这个 methods 对象）。 换句话说，Vue 现有的 API 在设计之初没有照顾到类型推导，这使适配 TypeScript 变得复杂。相比较过后，本 RFC 中提出的方案更多地利用了天然对类型友好的普通变量与函数。用该提案中的 API 撰写的代码会完美享用类型推导，并且也不用做太多额外的类型标注。 这也同样意味着你写出的 JavaScript 代码几乎就是 TypeScript 的代码。即使是非 TypeScript 开发者也会因此得到更好的 IDE 类型支持而获益。 composition api 文档官方 vue3 rfc rfc网站 setup函数用起来确实舒服，所有有用的东西都可以放在一块，代码整理也方便，不像以前一样需要分散到各种hook和计算属性、data函数中。但是也有我用起来不舒服的地方，基本类型和对象都需要使用ref函数和reactive函数进行包装，有的时候用起来就各种麻烦，需要多注意一些。不过这个问题倒不是什么大问题，和写c++的时候所有的对象用智能指针包裹一层一样，用多了就习惯了。 这是一个vue2的经典例子，通过data函数和计算属性来返回不同的数据。 在vue3中就可以全部集中到setup函数，并且一并返回，模板可以直接使用。 可以看出使用setup函数可以将模板所需的内容一块返回，结构更为清晰，vue2的模式也是可以的，只不过侧重点不一样，vue2的目的是一种动作的数据应该被放在一块，而vue3的setup函数则是将数据处理都放在一块，这样对数据的的整理比较方便和集中。 Propsprops是在组件上注册的自定义属性，当一个值传递给props的时候，它就会成为那个组件的一个property。 hello组件可以通过定义props函数来接收自定义属性。 这样就可以在helle.vue中使用message这个属性，不过需要注意的是，hello组件不要修改传递进来的message,否则会破坏数据的流向。 在vue3中使用会更加方便，因为类型推导更加方便。 在vue3和typescript中使用props需要有一些注意的地方，首先Props里需要设置值可能为空，否则setup函数的签名将无法匹配。其次访问props数据需要开启setup函数的props参数，还有一个context参数，可以访问上下文的内容。"},{"title":"JavaScript建造者模式","date":"2020-02-01T20:52:58.000Z","url":"/2020/02/01/JavaScript%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/","tags":[["Javascript","/tags/Javascript/"]],"categories":[["设计模式","/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"]],"content":"建造者模式就是指将类的构造和其表示分离开来，调用者可以通过不同的构建过程创造出不同表示的对象。主要解决在软件系统中，有时候面临着”一个复杂对象”的创建工作，由于需求的变化，这个复杂对象的某些部分经常面临着剧烈的变化，一些基本部件不会变。所以需要将变与不变分离。与抽象工厂的区别：在建造者模式里，有个指导者(Director)，由指导者来管理建造者，用户是与指导者联系的，指导者联系建造者最后得到产品。即建造者模式可以强制实行一种分步骤进行的建造过程。 建造者模式四要素 产品类Product: 一般是一个较为复杂的对象，也就是说创建对象的过程比较复杂，一般会有较多的代码。 抽象建造者类Builder: 将建造的具体过程交予它的子类来实现。 建造者类ConcreateBuilder: 组件产品，返回组件好的产品 指导类Director: 负责调用适当的建造者来组件产品，指导类一般不与产品类发生依赖关系，与指导类直接交互的是建造者类。 建造者模式的优点建造者模式的封装很好，使用建造者模式可以进行有效的封装变化，在使用建造者模式的场景中，产品类和建造者类是比较稳定的，因此，将主要的业务逻辑封装在指导者类中对整体可以取得比较好的稳定性。 建造者类也很方便扩展，如果有新的需求，只需要实现一个新的建造者类即可。 产品类 product.ts 抽象建造类 builder.ts 建造类 concreatebuilder.ts 指导类 director.ts 测试运行: 执行结果 通过不同的builder就可以构建不同的对象出来，当需求变动的时候，我们只需要扩展出不同的Builder和Director就可以满足。"},{"title":"浅谈Javascript构造器模式","date":"2020-01-31T23:15:23.000Z","url":"/2020/01/31/%E6%B5%85%E8%B0%88Javascript%E6%9E%84%E9%80%A0%E5%99%A8%E6%A8%A1%E5%BC%8F/","tags":[["Javascript","/tags/Javascript/"]],"categories":[["设计模式","/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"]],"content":"为了简化操作，JavaScript提供了new关键字。new关键字用于创建一个用户定义类型的实例，或者具有构造函数的内置对象的实例。 每当我们在一个函数调用前使用new关键字，该函数便会以一种特殊模式——构造模式来运行，在此模式中，JavaScript可以自动完成一些操作。基本上它是指解释器在你的代码中嵌入几行操作代码。 在JavaScript中，构造函数通常是认为用来实现实例的，但是JavaScript中没有类的概念，但是有特殊的构造函数，通过new关键字来调用定义的构造函数，你可以告诉JavaScript你需要创建一个新对象，并且新对象的成员声明都是构造函数里定义的。在构造函数内部，this引用的是新创建的对象。 上面是个很简单的构造函数模式，我们从字面上this是people对象，但是其实并不是这样的，new运算符帮助我们生成了this的初始化代码。 new运算符一共做了三件事： 创建一个空对象 将空对象的原型赋值为构造器函数的原型 更改构造器函数内部的this，将其指向新创建的对象 最后会经过一个判断，如果构造器函数设置了返回值，并且返回值是一个Object类型的话，就直接返回该Object，否则就会返回新创建的空对象。 总结一下： JavaScript没有类的概念，但是为了实现OOP，就通过new关键字实现对函数进行插入代码来实现对象实例的初始化。构造器模式就是通过一个方法来new出一个对象，这个操作就叫构造器模式。"},{"title":"2019 Review","date":"2020-01-01T21:25:54.000Z","url":"/2020/01/01/2019review/","tags":[["2019","/tags/2019/"]],"categories":[["年度总结","/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"]],"content":"上一次写年终总结还是18年回家的动车上，可惜写了一半没发表，觉得一年了没有什么能够回想起来的，就又删除了。今年不同了，今年有好多想说的。 脱单第一件重要的事是我遇到了生命中的她。 自从工作以后，我妈天天念叨我的就是找对象，和我预想的没错，上学的时候盼我毕业，毕业以后盼我工作，工作以后盼我找对象结婚，找对象以后盼我赶紧生个娃让她抱。（大家的父母应该都这样） 加薪这件事确实也令我挺开心的，我的工资在2019年成功涨到了0.375乔(1乔等于**元 @nanpuyue) 涨工资谁不高兴，我估计也就马云不高兴了，毕竟他看不上钱。 学习今年看了很多C++的资料，对C++和编译器都有了更深的了解。想2016年半夜@zccrs在家教我编译原理，到现在我可以理解一门语言从设计到实现，再到使用模板完成编译时计算，我走了快三年，这三年里我一直没停下学习的脚步，在学习各种知识，从各种编程语言到各种框架原理，到图形界面的实现。还学习了单元测试，并且@hualet大佬给我讲了单元测试是什么，以及单元测试的重要性，从那以后我才算真正的了解单元测试的重要性，也使我在写代码的时候注重通过单元测试来保障我的功能。 去年对深度学习进行了一波学习，今年对Web工程化和TypeScript也学习了一下，也算是对目前最热门的两个领域进行了一定的了解。 读书去年买的TensorFlow看了没一半，今年倒是没买书，开始在微信读书上读书，利用一些空余时间读一点，我也推荐大家多利用空闲时间读读书，少刷抖音和bilibili。 《TensorFlow》未读完 《TypeScript实战》正在读 博客2019年我一共水了15篇文章。 12-26 在ArchLinux通过串口调试VMware虚拟机中的deepin 12-26 使用标准库std::sort函数进行排序 12-09 记录一个坑爹的usb网卡 12-09 使用github actions自动部署hexo文章到html仓库 12-08 Vue父子组件传值 —— props &amp; $emit 12-08 添加Vue动画 11-25 使用webpack-dev-server来监听项目变化 10-24 给Archlinux开启BFQ和MuQSS 10-22 使用webpack打包Vue和TypeScript 10-14 webpack入门 06-16 wsl2的使用体验 06-15 入坑typescript了 05-23 CMake CTests for dde-control-center 02-21 如何在Deepin上使用LNMP 02-23 解决用了xposed后淘宝闪退 科普视频 妈咪叔 (一个较真的理工男) 这个名字我第一眼看到的时候，还以为是个卖母婴的，没想到居然是个搞科普的，而且内容讲的也很好，有数学、物理、化学和天文学。 李永乐老师 以前偶尔看过老师的视频，因为一直都在热榜，所以没想到关注，后来是youtube上看到了，就点了关注，youtube上更新的和bilibili的还不是一样的，看最后结尾的时候youtube的只说youtube帐号关注，而bilibili的是bilibili，有时候还要多个平台去看。 萝王二号 之前在科普区随便看的时候，对生物学产生了一些兴趣，萝王讲的风格我很喜欢，特别是他注重昆虫分类学(骨包皮，皮包骨啊2333)，还有一些辟谣视频。 芳斯塔夫 (鬼古) 也使对生物学产生了一些兴趣，鬼古说以他很中二的风格带领我学习了一波古生物的相关知识(旧日支配者！！！)。 木偶君 和鬼古一样是专门讲古生物的，不过每次结束的比较仓促，突然就结束了。 木鱼水心 木鱼并不是今年才关注的，最开始关注是他做EVA剧场版解析，后来《木鱼说》开始做一些科普，我开始一直关注了。 宇宙视觉 (永远不要停止思考) 一个讲天文的科普up，不过年底的时候换了配音，疑似配音出去单干了。 电影 流浪地球 阿丽塔：战斗天使 战狼2 惊奇队长 复仇者联盟4 何以为家 速度与激情： 特别行动 叶问4 纪录片 混沌：数学探秘 维度：数学漫步 动漫 刀剑神域 紫罗兰永恒花园 darling in the franxx 心理测量者 进击的巨人第三季 五等分的新娘 citrus～柑橘味香气～ "},{"title":"使用伪元素创建一个圆点","date":"2020-01-01T11:11:12.000Z","url":"/2020/01/01/%E4%BD%BF%E7%94%A8%E4%BC%AA%E5%85%83%E7%B4%A0%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%9C%86%E7%82%B9/","tags":[["CSS","/tags/CSS/"]],"categories":[["Web","/categories/Web/"]],"content":"我最早接触到CSS中的伪元素是在一次写背景模糊的时候，CSS中的blur会模糊下面所有的元素，但是可以通过伪元素在before中先模糊，这样下层是没有任何元素的，自然也不会有元素被模糊。 伪元素就如同它的名字一样，是假的元素，只是CSS引擎在排版的时候创建出来的，在DOM树中是不存在的，所以javascript是没办法操作伪元素的。伪元素分为before和after，可以在元素的前面或者后面创建一个假的元素，伪元素选择器的标志符号是::。 div::before 在div元素的前面创建一个元素，配合content属性一起使用。 div::after 在div元素的后面创建一个元素，配合content属性一起使用。 使用伪元素选择器需要注意一点的是，必须使用content属性，否则将不起任何作用。 伪元素选择器生效以后，可以在DOM中看到::before或者::after，这里提供一个例子。 html部分： css部分： 此时页面上会看到输出这么一句话，This is before Text, Text , This is after Text.，并且使用鼠标只能选择到最中间的Text文本。 代码可以点击这里查看。 今天写这篇文章呢，是因为今天我在实现hexo的Next主题，看到它在列表中使用after创建了一个小圆点，并且我遇到了一个问题，所以写这篇文章记录一下。 Next用的是浮动布局来实现的，而我决定flex一把梭，整体布局是垂直的flex，首页、分类等列表内部是用水平的inline-flex实现的，最左边是图标，来自fortawesome，中间的文本使用span包裹一下，实现左对齐，然后通过伪元素在最右边创建一个小圆点，设置a元素的宽度为100%，就可以实现圆点在最右边。 坑就是在这里遇到的，如果a元素的宽度设置为100%，伪元素创建的小圆点就不能完全显示，少1像素或者多1像素就可以完全显示。最终的解决办法是给小圆点的周围增加了1像素的padding解决了，但是原因位置，谁看到这篇文章并且恰好知道原因的，还请帮忙评论回复一下。 但我提取了基本结构和css，demo是能够正常显示小圆点的，但是自己的Vue却不能正常显示，后来发现是display写成块级元素用的flex了，改成inline-flex就能正常显示了，但是在调整宽度的时候，就发现了上面的问题，它又不正常显示了，实在解决不了了，就用padding处理了。 参考资料： 千古壹号"},{"title":"在ArchLinux通过串口调试VMware虚拟机中的deepin","date":"2019-12-26T17:26:13.000Z","url":"/2019/12/26/use-serial-port-debug-deepin-on-archlinux/","tags":[["Linux","/tags/Linux/"]],"categories":[["Linux","/categories/Linux/"]],"content":"电脑主板上的接口：进行串行传输的接口，它一次只能传输1Bit。串行端口可以用于连接外置调制解调器、绘图仪或串行打印机。它也可以控制台连接的方式连接网络设备，例如路由器和交换机，主要用来配置它们。消费性电子已经由USB取代串列接口；但在非消费性用途，如网络设备等，串列接口仍是主要的传输控制方式。 首先给虚拟机分配一个串口设备，选择Settings-&gt;Add-&gt;Serial Port。分配好串口设备以后，我们需要选择一个串口设备的调试方式，一个是将输出转向一个文件，或者是通过socket。 如果只是查看方式，选择outpu file即可。如果需要调试，则可以通过socket方式来进行。 socket方式需要给一个固定的路径分配/tmp/，我调试的时候给出的是/tmp/vhost，From选择Server，To选择An Application。From的意思是信息从哪里来，信息是虚拟机里的系统发出的，所以这里选择的是Server，如果是反向操作，需要选择Client。To也是有两个选项，第一个是An Virtual Machine，第二个是An Application。用于把消息发送给另外的虚拟机，或者是宿主机的一个应用程序。 安装minicom包，用于进行调试，minicom这个东西，不是太好用，退出方式是先按Ctrl+A，然后按q，有时候还不一定管用，不知道是没接受到，还是按错了。 先minicom -s 进行初始化，选择Serial port setup，按A编辑Serial Device，这里需要注意一下，通过socket进行调试，需要使用unix#前缀，然后加上在虚拟机里写的路径 unix#/tmp/vhost。然后保存，选择Exit，退出以后其实重启minicom，就进入minicom的调试界面了，然后此时开启虚拟机，给内核添加一个console=ttyS0的参数，就看到minicom显示输出的信息了，还可以交互。 此时就可以交互了，用法和tty一样，最后一行是minicom的输出，可以看到CTRL-A Z可以看help，minicom的版本，和访问的串口socket。"},{"title":"使用标准库std::sort函数进行排序","date":"2019-12-26T17:24:23.000Z","url":"/2019/12/26/cpp-sort/","categories":[[" ",""]],"content":"std的sort方法接受两个迭代器begin和end。通过迭代器来抽象元素的访问，隐藏内部实现。 这是一个简单的例子: 结果就是list被排序了，至于使用了什么排序算法，我们并不需要关心。实际上标准库会通过元素的数量来决定使用什么算法，基于Introspective Sorting(内省式排序)。它是一种混合式的排序算法： 在数据量很大时采用正常的快速排序，此时效率为O(logN)。 一旦分段后的数据量小于某个阈值，就改用插入排序，因为此时这个分段是基本有序的，这时效率可达O(N)。 在递归过程中，如果递归层次过深，分割行为有恶化倾向时，它能够自动侦测出来，使用堆排序来处理，在此情况下，使其效率维持在堆排序的O(N logN)，但这又比一开始使用堆排序好。 默认情况下排序是升序排序，既结果从小到大，我们可以通过使用std::equal_to、std::not_equal_to、std::greater、std::less、std::greater_equal和std::less_equal来控制排序。 以上是通过标准库内置的一些方式来控制排序，且适用于元素已实现了自定义比较(Compare)的要求。 比较 (Compare) 是一些标准库设施针对用户提供的函数对象类型所期待的一组要求。 对满足比较 (Compare) 的类型的对象运用函数调用操作的返回值，当按语境转换成 bool 时，若此类型所引入的严格弱序关系中，该调用的第一实参先于第二实参，则生成 true，否则生成 false。 与任何二元谓词 (BinaryPredicate) 相同，不允许该表达式的求值通过解引用的迭代器调用非 const 函数。 用人话来说就是，Compare必须提供出对比结果。 看一个例子: 这个例子提供了一个Compare，通过lambda来提供自定义的对比函数，返回值必须是bool，否则将不满足对比函数的要求。 通过以上三种方式可以看出，标准库的sort函数可以很方便的为使用者提供标准对比和自定义对比。如果元素自己已实现operator&lt;，则只需要使用标准库内置的对比函数即可，但是大部分情况其实并不会涉及到元素的排序，仅在临时情况下需要列表有序，所以我个人倾向于通过lambda提供Compare函数来完成列表的排序。 std::sort知无涯之std::sort源码剖析"},{"title":"记录一个坑爹的usb网卡","date":"2019-12-09T19:31:04.000Z","url":"/2019/12/09/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%AA%E5%9D%91%E7%88%B9%E7%9A%84usb%E7%BD%91%E5%8D%A1/","tags":[["Linux","/tags/Linux/"]],"categories":[["Linux","/categories/Linux/"]],"content":"网卡型号是Realtek RTL8811CU/RTL8821CU USB Wi-Fi adapter，买来是为了让黑苹果上网的，windows下也会自动下载和安装驱动，但是linux比较难受，内核不提供这样的驱动，只能去官方拿源码搞，今天在arch上打算装一下驱动，结果遇到了很多问题。 wiki上推荐的8821应该使用rtl88xxau-aircrack-dkms-git，但是我安装以后压根不能用，一点变化都没有，而且modprobe也没有作者给出的88XXau，无奈只得放弃。 继续谷歌之，在看到了别人给的方案，然后果断clone并make,然后就因为没有适配5.x的内核编译失败，这可不行，翻了一下issue，看到作者在提到了一个#23，这标题写的够可以，Newer version 5.4.1 (Support Linux versions from 4.4.x up to 5.4.x) ，赶紧搞起，去源地址clone和make,成功使用上了驱动，按照作者提到的安装usb_modeswitch，并切换usb模式，我成功的使用上了这个usb网卡。 吐槽一下，开发环境还是linux下舒服，仓库的包安装一下就可以开发了，windows下要自己写路径，mac下brew限制太死，一些库安装以后还要自己手动做些处理，一不小心就把shell的环境变量搞不行了，或者压根不能正常工作。 "},{"title":"使用github actions自动部署hexo文章到html仓库","date":"2019-12-09T13:19:11.000Z","url":"/2019/12/09/use-github-actions-to-depoly-hexo/","categories":[[" ",""]],"content":"请先允许我大喊一声：微软牛逼！ 本文没有啥含金量，就是简单的说一下如何部署github-actions来自动生成hexo的public，并且再推送到html仓库的。 我的博客仓库一共分为两个，blog仓库是私有的，需要通过我的私钥才能访问，html仓库是公开的，hexo生成的静态内容会被上传到这里。 首先在package.json中添加一些命令，方便我们一键编译和提交: 因为CI环境需要提交代码到仓库，所以申请一个个人用的token，访问创建一个新的，勾选上repo，生成完token以后，修改一下_config.yml中对deploy仓库的url，格式固定为:你的token@github.com/你的名字/仓库名.git,例如我这里是。 然后新家一个github actions，选择nodejs环境，我们只需要修改最后一个步骤，执行我们自己的命令即可。 设置git的用户名和邮箱地址 npm install -g yarn yarn run deploy 如果你还有一些其他步骤，可以自行扩展，比如我就有主题相关的操作，具体的内容如下: 然后就可以愉快的自动部署了。"},{"title":"Vue父子组件传值 —— props & $emit","date":"2019-12-08T21:08:00.000Z","url":"/2019/12/08/vue-component-props/","tags":[["Vue","/tags/Vue/"]],"categories":[["Vue","/categories/Vue/"]],"content":"Vue的父子组件传值比较有意思，父组件通过属性绑定，把自身的值和子组件的一个属性绑定起来，子组件通过props属性接收，该属性类型为数组，是Vue对象中比较少有的类型，data、computer、methods等方法都是对象的形式，props则是数组的形式。父组件通过v-on来监听子组件发出的事件来接收子组件的调用。在这里我是理解成子组件发送信号来通知上层，毕竟调用的是this.$emit来做到的。 我们假设子组件名为，我们通过v-bind来绑定一个值给它。 子组件hello.vue通过props属性接收，内容是这样的： 这里有个需要注意的地方，父组件给子组件的数据是单向的，虽然子组件也可以修改父组件传入的数据，但是会产生一个错误，并打印在终端里。 那么我们怎么才能修改父组件的值呢？答案是this.$emit。 我们给子组件绑定上v-on，来监听子组件的事件。 子组件只需要发送出修改即可： 以上就是Vue父子组件传值的一种常用方法，适用于相邻组件的，如果隔代了，那么这种方式就不好用了，中间路过的组件都需要转发这个事件，处理这种情况就需要使用provide/ inject了，不过那就是另一篇文章啦。"},{"title":"添加Vue动画","date":"2019-12-08T08:03:40.000Z","url":"/2019/12/08/vue-transitions/","tags":[["Vue","/tags/Vue/"]],"categories":[["Vue","/categories/Vue/"]],"content":"以前一直搞不懂动画是怎么做的，它怎么这么神奇，写了一点看不懂的代码，就实现了非常丰富的效果，现在做了三年Qt开发，接触到了Qt的动画类，明白了动画是怎么一会儿事，现在来看当初的css动画代码，也明白了它是如何工作的了。本文会介绍一下Vue提供的组件过渡动画模块——transitions。 概述Vue在插入、更新和移除DOM元素时，提供了多种不同方式的应用过渡效果。包含以下工具： 在css过渡和动画中自动应用class 可以配合第三方动画css类，例如Animae.css 提供钩子函数来使JS操作DOM元素 可以配合使用第三方JavaScript动画库，例如Velocity.js 单元素/组件过渡Vue提供了 transitions 的封装组件，在下面的情况中，可以给任意元素或组件添加进入和离开的过渡效果。 条件渲染 (使用 v-show) 按需渲染 (使用 v-if) 动态节点 组件根元素 这是一个基本的例子： 在head中添加style： 这里有三点需要注意一下，需要动画的元素需要使用transitions节包裹起来，transitions需要一个name，css中需要使用固定的拼写来应用动画，入场动画和离场动画的状态是一致的，所以写在了一组里。 当插入和删除包含在 transitions 组件中的元素时，Vue会做以下的事情： 自动嗅探组件是否应用了css的过渡或动画，如果有，则在恰当的实际添加/删除css类名。 如果 transitions 组件提供了钩子函数，Vue会在恰当的时机调用钩子函数。 如果没有找到css过渡和动画，也没有找到钩子函数，则DOM的操作(插入和删除)在下一帧中立即执行。(注意是指浏览器的逐帧动画，而不是Vue的nextTick机制) 过渡的类名Vue的过渡动画一共有6个状态： v-enter: 定义进入过渡的开始状态，在元素被插入之前生效，待元素插入以后被移除。 v-enter-active: 定义进入过渡生效时的状态，在整个进入过渡的阶段中应用，在元素插入之前生效，在过渡/动画完成后被移除。这个类可以定义过渡时间、延迟和动画曲线。 v-enter-to: 在2.1.8版本及以上 定义进入过渡的结束状态，在元素被插入的下一帧生效(与此同时 v-enter 被移除)，在过渡/动画完成后移除。 v-leave: 定义离开过渡的开始状态，在离开过渡被触发时立即生效，下一帧被移除。 v-leave-active: 定义离开过渡生效时的状态，在整个离开过渡的阶段中应用，在离开过渡触发时立即生效，在过渡/动画完成后立即被移除。这个类可以定义离开过渡的过程时间、延迟和动画曲线。 v-leave-to: 在2.1。8版本及以上 定义离开过渡的结束状态，在离开过渡被触发之后的下一帧被移除(与此同时v-leave也被删除)，在过渡/动画完成之后移除。 可以看出一共两组动画，进入和离开的active。并且分别有两个状态，enter和enter-to，这6个状态控制了入场动画和离场动画。(吐槽一下Qt的动画系统，定义一个QAnimation只能做半场动画，想做到Vue这样的要定义两组，或者反向播放) 对于那些正在过渡中切换的类名来说，如果使用了没有name属性的transition，Vue会使用v-当做默认前缀。为了避免多组动画冲突，我个人建议每一个transition组件都提供name属性。 JavaScript钩子函数transition也提供了钩子函数，使我们可以通过JavaScript来控制DOM元素，一共也包含了8个函数： beforeEnter enter afterEnter enterCancelled beforeLeave leave afterLeave leaveCancelled 和css上要求的命名保持一致，只是增加了两个取消的接口，当动画被取消的时候被调用。 这些钩子函数可以结合CSS transition/animations 使用，也可以单独使用。 当只使用JavaScript过渡的时候，必须在 enter 和 leave 显式调用done()进行回调，否则他们将被同步调用，过渡会立即完成。 推荐对于仅使用JavaScript过渡的元素添加v-bind:css=&quot;false&quot;，Vue会跳过CSS的检测，这也可以避免过渡过程中css的影响。 列表元素的过渡以上我分享的都是单元素/组件的过渡，那么问题来了，列表这种通过v-for创建的元素该如何增加过渡效果呢？ Vue提供了&lt;transition-group&gt;组件，在深入了解之前，需要先介绍一下这个组件的一些特点： 不同于&lt;transition&gt;，&lt;transition-group&gt;会创建一个真实的DOM元素，默认是，可以通过tag属性切换为其他元素。 过渡模式不再可用，因为我们不再相互切换特有的元素 内部元素总是需要提供唯一的key值来进行区分 CSS过渡将会应用在内部的元素中，而不是这个组/容器本身 列表的进入/离开过渡 代码在这里，点击访问，只实现了添加元素的过渡效果。 希望本文可以帮助你理解Vue是如何处理过渡动画，本文是基于官网的知识和demo所编写的，本文只写了一部分我觉得需要掌握的基本功能，Vue的transition组件还有很多功能等待你的挖掘，点击前往Vue官网文档"},{"title":"使用webpack-dev-server来监听项目变化","date":"2019-11-25T17:54:36.000Z","url":"/2019/11/25/%E4%BD%BF%E7%94%A8webpack-dev-server%E6%9D%A5%E7%9B%91%E5%90%AC%E9%A1%B9%E7%9B%AE%E5%8F%98%E5%8C%96/","tags":[["Vue","/tags/Vue/"]],"categories":[["Vue","/categories/Vue/"]],"content":"webpack的出现方便了前端开发者，使开发和部署分成了两部分，开发者可以正常根据工程化的要求进行开发，部署时通过webpack实现代码的裁剪和优化。 本次就介绍一个webpack的功能 webpack-dev-server 将webpack与提供实时重载的开发服务器一起使用。这仅应用于开发。它在后台使用了webpack-dev-middleware，它提供了对Webpack资产的快速内存访问。 webpack-dev-server提供了一个小型的express的http服务器，这个http服务器和client使用了websocket通讯协议，原始文件作出改动后，webpack-dev-server会实时的编译，但是最后的编译的文件并没有输出到目标文件夹。 注意：启动webpack-dev-server后，在目标文件夹中是看不到编译后的文件的,编译后的文件都保存到了内存当中来加速访问。 启用webpack-dev-server 在webpack.config.js中添加devServer对象： 然后通过npx webpack-dev-server启动，终端上会输出一些信息，一般我们会增加一些参数来使输出更加好看: 上面的命令增加一个开发工具 eval-source-map，开启了progress进度显示，开启了colors颜色，hot热更新和inline更新模式。上面的参数也可以添加到devServer的属性中。 终端输出的内容如下: 我们就可以通过localhost:9000来访问我们的应用了。 需要注意的是，由于我们经常把内容输出到dist目录，但是webpack运行是在项目目录的，访问webpack生成在dist目录的main.js时，需要写上相对于webpack的目录，例如dist/main.js。否则会找不到文件。 如果遇到问题，导航到 /webpack-dev-server 路径，可以显示出文件的服务位置。 例如，。 配置webpackwebpack-dev-server支持在服务内部调用中间件对数据进行处理。 devServer.beforefunction (app, server) 在服务内部的所有其他中间件之前， 提供执行自定义中间件的功能。 这可以用来配置自定义处理程序，例如： devServer.after同devServer.before，在服务内部的所有中间件之后，提供执行自定义中间件的功能。 devServer.allowedHosts允许添加白名单服务，允许一些开发服务器访问。 模仿 django 的 ALLOWED_HOSTS，以 . 开头的值可以用作子域通配符。.host.com 将会匹配 host.com, www.host.com 和 host.com 的任何其他子域名。 devServer.clientLogLevelstring: &#39;none&#39; | &#39;info&#39; | &#39;error&#39; | &#39;warning&#39; 当使用内联模式(inline mode)时，会在开发工具(DevTools)的控制台(console)显示消息，例如：在重新加载之前，在一个错误之前，或者 模块热替换(Hot Module Replacement) 启用时。默认值是 info。 devServer.clientLogLevel 可能会显得很繁琐，你可以通过将其设置为 ‘none’ 来关闭 log。 devServer.color - 只用于命令行工具(CLI)只在终端下启用，启用/禁用控制台的彩色输出。 devServer.compressboolean 一切服务都开启gzip压缩。 devServer.contentBaseboolean: false string [string] number 告诉服务器从哪个目录中提供内容。只有在你想要提供静态文件时才需要。devServer.publicPath 将用于确定应该从哪里提供 bundle，并且此选项优先。 默认情况下，将使用当前工作目录作为提供内容的目录。将其设置为 false 以禁用 contentBase。 也可以从多个目录提供内容： devServer.disableHostCheckboolean 设置为 true 时，此选项绕过主机检查。不建议这样做，因为不检查主机的应用程序容易受到 DNS 重新连接攻击。 devServer.filenamestring 在 lazy mode(惰性模式) 中，此选项可减少编译。 默认在 lazy mode(惰性模式)，每个请求结果都会产生全新的编译。使用 filename，可以只在某个文件被请求时编译。 如果 output.filename 设置为 ‘bundle.js’ ，devServer.filename 用法如下： 现在只有在请求了bundle.js时，才会去编译bundle。 总结webpack的功能确实很强大，可以针对代码进行各种操作，最终生成出可以适应各种场景的代码，使开发和部署彻底分离开来，开发者可以更加专注项目。"},{"title":"给Archlinux开启BFQ和MuQSS","date":"2019-10-24T13:19:21.000Z","url":"/2019/10/24/%E7%BB%99Archlinux%E5%BC%80%E5%90%AFBFQ%E5%92%8CMuQSS/","tags":[["Linux","/tags/Linux/"]],"categories":[["Linux","/categories/Linux/"]],"content":"最近在Arch上更新系统的时候，总是遇到图形完全卡住的情况，今天上午突然想起来自己曾经设置了使用noop的IO调度，猜测是因为这个。然后本着不折腾不舒服的原则，打算使用ck内核上MuQSS的进程调度和BFQ的IO调度。 ck内核并没有在arch的仓库，但是aur有linux-ck的包，安装一下就可以了。 编译需要一些时间，在我的破本子i7-8550U编译了一顿过桥米线的时间，然后成功使用了ck内核。 开启MuQSSck内核默认使用的就是MuQSS调度，并不需要修改什么，开机即可。 开启BFQ开启BFQ需要一些手动设置。分为两步： 修改grub，给内核提供新的参数 使用udev开启动态调整 修改grub 编辑/etc/default/grub中GRUB_CMDLINE_LINUX_DEFAULT，增加一行内容: 然后更新grub配置文件: 创建udev规则 创建并编辑/etc/udev/rules.d/60-scheduler.rules 上面的配置是给固态硬盘使用deadline，给机械盘使用bfq，给nvme盘bfq。 本着电脑只有ssd，所以天不怕地不怕的原则，我选择全部使用bfq。 然后重启电脑，查看所有硬盘的调度器： 通过dmesg查看MuQSS是否开启： 总结MuQSS是BFS(脑残调度器)的进化版，主要是改进了BFS的O(n)复杂度，BFS适用于桌面环境用户，可以提供较好的进程切换和延迟。BFQ是针对硬盘的IO调度，它通过预先分配一定的IO吞吐量来合理安排每个进程的IO操作。我需要用几天来感受一下MuQSS和CFQ的好处。"},{"title":"使用webpack打包Vue和TypeScript","date":"2019-10-22T15:20:08.000Z","url":"/2019/10/22/%E4%BD%BF%E7%94%A8webpack%E6%89%93%E5%8C%85Vue%E5%92%8CTypeScript/","tags":[["Vue","/tags/Vue/"],["Webpack","/tags/Webpack/"],["TypeScript","/tags/TypeScript/"]],"categories":[["Web","/categories/Web/"]],"content":"本文将会介绍如何通过Webpack将基于TypeScript的Vue项目进行打包。 webpack基础配置首先创建一个基本的webpack.config.js文件: 此时webpack只能将src/index.ts文件直接输出为index.js，我们需要添加typescript的loader，进行typescript的转换。 将以下代码加入rules节: 通过ts-loader进行ts文件的转换，我们还需要创建typescript的一个配置文件。 添加typescript支持创建tsconfig.json 还需要在webpack的配置中添加ts文件，在resolve节中添加: 我们指定ts转换出的js代码是es5的。 这个时候我们运行webpack，将会看到正常的转换输出。 入口文件就是index.ts了，之后我们就正常的在index.ts中写我们的代码，webpack就会查找所有的依赖，并打包输出到index.js中。 添加Vue单文件的支持Vue单文件组件(SFC)规范是指在一个文件中，提供html、css和script代码，三者包含在顶级语言块 &lt;template&gt;、&lt;script&gt; 和 &lt;style&gt; 中，还允许添加可选的自定义块。 这是一个简单的vue单文件例子: 我们通过vue-loader来解析该文件，提取每一个语言块，如有需要，会传递给其他loader进行处理，最后组装为一个ES Module。 我们在webpack的rules节中添加vue-loader: 如果vue是typescript代码？其实这很简单，ts-loader有一个appendTsSuffixTo的功能，可以给某个文件增加.ts的后缀，从而识别这个文件为ts文件。 我们还需要在项目中添加一个vue-shim.d.ts来让ts正确的识别vue。 还需要在webpack的resolve节追加vue的后缀: vue-loader现在需要手动处理一下插件，在webpack.config.js的头部导入vue-loader，并在plugins节创建对象。 否则将不能正确工作。 此时已经完成了webpack+vue+typescript的全部工作。 "},{"title":"webpack入门","date":"2019-10-14T15:34:52.000Z","url":"/2019/10/14/webpack%E5%85%A5%E9%97%A8/","tags":[["Web","/tags/Web/"]],"categories":[["Web","/categories/Web/"],["webpack","/categories/Web/webpack/"]],"content":"现在前端开发不像以前一样，只需要写html、css和javascript文件就可以了。现代前端开发讲究工程化。 什么是工程化？ 工程化即系统化、模块化、规范化的一个过程。 为什么要工程化？ 工程化是让开发、测试和维护都变得更加可靠和提高效率的方式。 制定规范 版本管理 单元测试 自动化 通过制定流程的方式，规范了开发和测试的流程，让工作有章可循，方便团队协作。 最初的网页开发，是写好几份的javascript代码和css文件，手动在html中引入的。这样不适合多人协作开发，一旦开发人员多了，不可避免的会造成文件和命名冲突。为了避免这些事情的发生，javascript增加了模块的概念。 有好的事情出现，就会有坏的事情发生。 过多的模块导致js文件下载很慢，而且有冗余，为了避免这件事情影响用户体验，webpack横空出世了。 webpack是一个现代javascript的静态模块打包器。它会递归的构建出依赖图，并根据依赖图来输出应用程序需要的每个模块，然后将所有这些模块打包成一个或多个 bundle。 webpack有四个核心概念: 入口(entry) 输出(output) loader 插件 入口决定了webpack要从哪个文件开始构建依赖图。 看一个简单的例子: output则决定了webpack会在哪里输出生成的bundles，以及如何命名这些bundles。输出目录默认为 ./dist/ 。 loader可以让webpack打包非javascript文件，loader可以将所有类型的文件转换为webpack可以识别的有效模块，然后利用webpack的打包能力，对他们进行处理。 rules中的意思是，当require()/impot中被解析为.css的路径时，先使用css-loader转换一下。 我们可以开发新的loader去加载不同的文件，最终都通过webpack来打包到一起。 loader用于转换某些类型的模块，插件则工作的更加广泛。插件的范围包括，从打包优化和压缩，一直到重新定义环境中的变量。插件接口功能极其强大，可以用来处理各种各样的任务。 想要使用一个插件，你只需要 require() 它，然后把它添加到 plugins 数组中。多数插件可以通过选项(option)自定义。你也可以在一个配置文件中因为不同目的而多次使用同一个插件，这时需要通过使用 new 操作符来创建它的一个实例。 总结通过webpack，我们可以将整个项目都打包为一个文件进行分发，而且还可以进行优化。webpack的出现，将前端的开发和发布彻底的分离开，开发人员可以以各种方式进行开发，通过webpack打包以后输出部署需要的文件。"},{"title":"wsl2的使用体验","date":"2019-06-16T12:59:59.000Z","url":"/2019/06/16/wsl2%E7%9A%84%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/","tags":[["Windows","/tags/Windows/"]],"categories":[[" ",""]],"content":"wsl2已经是虚拟机平台了。 需要Windows版本在18917及以上，先开启虚拟机平台才能继续，在管理员权限的powershell中执行 对已安装的wsl1进行转换 Distro可以通过 wsl --list 查看。 转换需要点时间，完成以后就可以浪起来了。 wsl2新增了一些参数： wsl --set-version &lt;Distro&gt; &lt;Version&gt; 可以设置某个wsl的版本，1是旧版，2是新版。 wsl --set-default-version &lt;Version&gt; 设置默认的wsl版本，推荐设置一下。 wsl --shutdown 出于某些目的，比如已经完成了任务，不再需要wsl工作在后台，可以手动关闭。 wsl --list --quiet 仅列出分发名称，此命令对于脚本编写很有用，因为它只会输出您已安装的发行版的名称，而不显示其他信息，如默认发行版，版本等。 wsl --list --verbose 显示有关所有分发的详细信息。此命令列出每个发行版的名称，发行版所处的状态以及正在运行的版本。它还显示哪些分发是默认的星号。 当一切准备就绪，我就安装了docker，测试一波。 添加用户到docker组。 已经可以跑docker了，我们来做个测试，请出万能的hello world！ 然后就看到了想要的结果，hello world成功的跑起来了。 总的来说，因为wsl2改成虚拟机方案了，不过wsl2的启动速度还是挺快的，微软也努力让wsl2和wsl1之间在使用上没有差异。目前微软还没有完成wsl2的网络部分，wsl2和宿主机之间还需要使用专门的ip进行访问，等微软完成wsl2的localhost网络以后，就可以像以前一样直接跑一些网站或者需要端口的服务了。 来一张合照 点我查看wsl2的发布说明 点我查看如何安装wsl2"},{"title":"入坑typescript了","date":"2019-06-15T23:41:49.000Z","url":"/2019/06/15/%E5%85%A5%E5%9D%91typescript%E4%BA%86/","tags":[["typescript","/tags/typescript/"]],"categories":[[" ",""]],"content":"今天算是正式入坑 typescript 了，基于 vue 写了第一个函数，用来做一个文字效果。 演示效果： 整体思路听简单的，就是用定时器和延时器来做，通过定时器来间隔的处理文本，延时器来延后所有的方法。 typescript确实挺不错的，平时都在写静态语言，如C++，所以当我开始学动态语言的时候，就会觉得水土不服，现在通过typescript就可以让我继续使用静态语言的开发方式来写web，而且代码更容易理解。"},{"title":"CMake CTests for dde-control-center","date":"2019-05-23T17:16:15.000Z","url":"/2019/05/23/CMake-CTests-for-dde-control-center/","tags":[["CMake Linux","/tags/CMake-Linux/"]],"categories":[["Linux","/categories/Linux/"]],"content":"什么是单元测试? 在计算机编程中，单元测试又称为模块测试，是针对程序模块（软件设计的最小单位）来进行正确性检验的测试工作。 单元测试存在的意义在于，如果程序发生了异常情况，比如接收了错误的值，从而导致结果不正确，当修正程序中的错误后，为了避免再次遇到这个问题，需要对出问题的值和函数/功能进行一次测试，确保结果符合预期。 单元测试很重要，如果是新项目，请一定要刚开始就规划好单元测试。 为什么说单元测试很重要呢？因为单元测试的目的是隔离其他单元，并证明当前单元是正确的。这需要开发者在设计程序的时候就要考虑很多，合理的设计和规划项目。当未来重构项目的时候，可以局部重构来优化项目，而不是从零重写。 本文没有详细说明Qt的单元测试是如何编写的，编写Qt的单元测试放在以后再写(咕咕咕)。 写这篇文章是因为最近在给控制中心写单元测试，控制中心的模块都是MVC的，本身就做好了大方向的隔离，每个函数也基本是拆分出来的最小功能，可以单独拿出来测试。控制中心目前存在一个问题，Worker类是从DBus上接收数据，处理完成后放入Model中，如果测试Worker类，需要做很多和DBus相关的处理，比较麻烦，所以最开始我先把重心放在了创建Tests和测试一个基本的转换函数的功能，验证单元测试的流程。 控制中心单元测试PR 控制中心项目使用的CMake作为项目构建工具，所以用到了CTests，控制中心使用的Qt进行的开发，Qt也提供了自己的单元测试，我两个都做了支持。 在顶层的CMakeLists.txt中添加CTests的支持： 这两行内容需要在顶层CMakeLists.txt中添加，不然不会生效。 在子项目中创建一个dcc_test.h，用来写单元测试的类。 在子项目的CMakeLists.txt中添加一个二进制，用来当作单元测试程序。 到这里，直接编译启动unit-test就可以使用Qt的单元测试了，但是加上CTest的支持只需要一行： 使用ctest -j6 -C Debug -T test –output-on-failure跑CTest，得到执行结果： 如果是跑unit-test二进制，则会得到Qt打印的相关信息： 对比CTest和Qt的单元测试，Qt会告诉你详细的函数调用和执行过程，CTest更注重结果，不过在Qtcreator的单元测试面板中，会看到更好的输出。 说到底，CTest支持启动了一个带有单元测试的程序，而程序自己使用了Qt提供的单元测试类进行测试。"},{"title":"如何在Deepin上使用LNMP","date":"2019-02-21T10:11:15.000Z","url":"/2019/02/21/how-to-use-LNMP-on-deepin/","tags":[["Linux","/tags/Linux/"],["LNMP","/tags/LNMP/"],["Deepin","/tags/Deepin/"],["Web","/tags/Web/"]],"categories":[["Linux","/categories/Linux/"]],"content":"为了节省读者的时间，我先简述一下阅读这篇文章需要了解的知识。 这篇文章将基于Docker来构建nginx、php和mysql来搭建LNMP环境，和其他教程有所不同的是，需要有一定的Docker基础。 Docker是一个不错的工具，使我们不需要虚拟机那样的庞然大物就可以轻松的隔离运行的程序，这要感谢Linux的资源分离机制，避免启动一个虚拟机造成了大量资源浪费。 首先需要在Deepin上安装Docker，添加Docker的deb仓库，并安装docker-ce。 创建文件 写入 刷新一下仓库就可以安装了。 安装完成后重启一下系统，准备工作就算完成了一半了。 在家目录创建一个Projects目录，当做我们LNMP的工作目录，创建一个名叫docker-compose.yaml的文件，这是docker-compose的配置文件，我们通过docker-compose这个工具来管理我们的Docker容器。 所有的镜像均采用最新版本，nginx(1.15.8)，php(7.3.2)，mysql(8.0.15)，如有需要，自行选择不同版本的镜像。 注意PHP7已经不支持mysql扩展，使用内置的MySQLnd。 写入以下配置文件： 创建nginx的配置文件，编辑 ./volumes/nginx/conf.d/nginx.conf ： 创建php测试文件，编辑 ./volumes/html/index.php : 启动docker，第一次需要拉取一下镜像: 等全部结束以后，就可以访问localhost看到php的信息了。 通过Docker的方法来使用LNMP，不污染宿主机环境，不会再因为各种依赖问题而搞坏系统，这恰恰是新手容易犯的错误，使用Docker，方便你我。"},{"title":"解决用了xposed后淘宝闪退","date":"2019-01-23T10:27:52.000Z","url":"/2019/01/23/fuck-taobao/","categories":[[" ",""]],"content":"反正都用xposed了，肯定也有root权限。删除/data/data/com.taobao.taobao/files/bundleBaseline/里的文件，然后设置该目录为500。"},{"title":"使用swapfile来休眠","date":"2018-12-12T11:01:55.000Z","url":"/2018/12/12/hibernate-for-swapfile/","tags":[["Linux","/tags/Linux/"]],"categories":[["Linux","/categories/Linux/"]],"content":"最近deepin要添加休眠功能，但是之前测试的通过swapfile来休眠失败了，所以对正在使用swap分区的用户提供休眠功能。但是昨天我在askubuntu上看到有人发了在ubuntu下通过swapfile休眠的方案，今天试了一下，效果良好，觉得可以考虑给deepin也加上这样的功能。 原文链接: Hibernate and resume from a swap file 具体步骤是通过uswsusp这个包来做的，uswsusp是一组用户空间工具，用于Linux系统上的休眠(挂起到磁盘)和挂起(挂起到RAM或待机)。详细内容可以在ArchWiki上参考。点这里 先创建一个和内存同等大小的swapfile，为了确保休眠成功，不能小于内存的容量。 安装用户空间软休眠(Userspace Software Suspend)包 创建需要的配置文件，只需要创建文件即可。 这时候终端会提醒是否继续，选择Yes，然后会要求你创建一个密码，设置一个密码继续即可。 此时就可以测试一下功能了，不过我是跳过这个步骤了(比较喜欢作死)。 修改systemd的hibernate服务，使用uswsusp来代替systemd的功能。 写入以下内容: 这时候可以使用systemd的命令来测试的，我表示工作的非常正常。 执行以后可以看到屏幕上会打印当前保存的进度，然后设备就关机了，此时再开机，等待一会儿以后就看到了背景是我漂亮老婆的锁屏，解锁以后看到工作区还是执行命令前的，一切ok。 参考以下内容:   "},{"title":"C++快速排序","date":"2018-11-11T16:57:44.000Z","url":"/2018/11/11/quick-sort-for-cpp/","tags":[["C++","/tags/C/"],["Program","/tags/Program/"]],"categories":[[" ",""]],"content":"快速排序是基于分治思想的排序算法，通过这种策略把列表分为两个子列，重复该过程。是由东尼·霍尔提出，在平均状况下，排序N个数据要O(nlogn)次比较，在最坏情况下则需要O(n^2)，但退化成冒泡的情况比较少见，快速排序比其他排序算法通常情况是最佳的，因为内部使用的循环在很多平台都有优化。 快速排序的步骤很简单： 选择一个基准 遍历列表，将小于基准的放在列表左边，大于基准的放在列表右边 递归这个操作 在维基百科上的这张图可以很直观的展示快速排序的过程。 代码实现: 首先需要一个返回基准的函数，该函数负责从指定的范围中挑选一个位置作为基准，并对范围内列表进行排序，并返回基准所在的位置。 Division函数只做了最简单的事，找一个基准，并交换左右的元素，使列表左侧均小于基准元素，使右侧均大于基准元素，接下来需要一个函数，使列表趋向最小，直至列表元素剩一(这里我感觉其实有点极限的思想)。 配合上方的gif，就可以很清楚的了解快速排序是如何使用分治法来排序的，通过将大任务拆分成小任务，最终达成完整的排序."},{"title":"使用Google日历安排工作任务","date":"2018-11-09T21:15:45.000Z","url":"/2018/11/09/use-google-calendar-to-finishe-work/","categories":[[" ",""]],"content":"目前我们正在尝试把工作的分配和讨论放在github上进行，这样可以使我们的用户和开发者更容易接触到我们，可以提bug和对需求进行讨。 但是使用起来还是有些不便，比如使用tower进行任务分配的时候，可以方便的移动一个任务到某个分类，或者指派一个时间。但是github上是基于issue的，并不是为了做这种事来设计的，所以需求上有一些出入。但是@hualet大佬根据github的api写了一个bot来做一点微小的事，当一个issue的assignees只剩QA的同事时，issue会被bot移动到测试栏中，只剩一个开发同事时(基本上是负责该任务的开发者)，会被移动到开发栏中。 但是因为不能做到比如今天、明天、下周等时间的显示，所以任务只能通过每天开会来口头告知时间，但是这并不妨碍我进行自己的任务时间安排。请出世界第一的神器(日历)。 我选择使用谷歌日历，才不是因为它有网页还有安卓客户端【哼 谷歌日历上支持新建三种类型，分别是活动、提醒和任务。活动是开始时间明确，但是结束时间未知的类型，适合用作对时间不严格的情况。提醒则是在活动的基础上添加了提供功能，在活动即将开始时发送通知提醒。任务则是熟悉的ToDoList，适合用来分配今天一定要做，但是时间未知的事。 我添加了每天的开会提醒，再开完会以后，我会把身上的新任务创建成task，然后再添加大概的活动来确定一下要完成的task。把今天没有时间做的task移动到明天，留在当天的task尽量要当天完成，可以得到今天的任务列表和延期列表，让我对要做的事有完整的控制。 谷歌日历的日视图和周视图会显示一条线，告诉你现在的时间，应该进行什么活动了。 在手机上需要使用两个app，Google calendar和Google task，活动和提醒需要calendar，task则需要单独使用一个app，只有网页上才是整合的。 因为我也是才开始用日历来分配任务的时间，所以记录的内容并不多，我也在摸索如何使用这些功能，但是我觉得使用日历来记录和管理时间是非常不错的一件事，我可以通过看某天的活动来回忆当天所做的事，也可以根据记录的内容来分析自己在某些任务上使用了多少的时间。"},{"title":"把博客转移到coding","date":"2018-11-09T20:17:32.000Z","url":"/2018/11/09/hexo%20page%20move%20to%20coding/","categories":[[" ",""]],"content":"上周末折腾黑果子的时候，不小心被果子坑爹的磁盘管理坑了，整个home被直接改成HFS+了，本来是打算分配一个空闲分区出来的，当我新建分区以后，从空间分区开始到home，分区全部都变成HFS+了，但是… 空闲分区新建失败，提示我磁盘空间不足，我就重启进deepin打算直接新建一个算了，然后就GG几率了。在windows下看到home已经成果子的文件系统了，然后我用arch的安装盘看了一下，已经无法重新挂载了(成功GG)，然后数据就都没了。 还好我的数据在公司还有一份，私钥也都在，经过一星期的努力复制，大部分数据都恢复了，不过topbar的新功能代码是彻底没了，周五晚上太自信了，没有提交到gayhub上(猛叹气)。 我们现在正在尝试把日常工作转向github的project和看板，每天早上开一下晨会，简单分配一下任务，开完会以后我会把自己的任务写在谷歌日历和task上，然后安排一下任务的先后顺序，我准备把自己的一些做法写到博客上，但是home已经不在了，所以我要先恢复我的博客，刚好国内有人说我博客访问的很慢，我打算国内解析到coding，国外解析到github。 首先，创建新的博客目录，用来拉取旧的数据。 初始化git目录。 添加远程仓库。 取回origin的backup分支，和本地master合并。因为hexo-git-backup插件只支持master，但是coding只支持master部署page服务，所以需要使用其他分支。 拉取了代码以后，我们需要做点其他设置，首先设置上游分支。 设置git的默认push策略，可以参考thekaiway的文章。 然后添加coding的git地址。 之后就正常使用了，通过npm安装hexo，再安装需要的插件，最后完成了在一台新电脑上恢复hexo博客。"},{"title":"智能指针","date":"2018-08-29T09:43:17.000Z","url":"/2018/08/29/cpp-smart-pointer/","tags":[["C++","/tags/C/"]],"categories":[["C++","/categories/C/"]],"content":"其实一直都对智能指针的应用场景不清楚，项目中也很少用到，今天在 @zccrs 大佬的帮助下，大概理解了智能指针的作用和应用场景。 设计思想智能指针依赖一种叫引用计数的手段来协助管理对象指针，通过引用计数为0时删除对象指针来完成内存的释放，本质上是通过栈对象来管理堆对象的一种方法。 传统做法 当出现异常时，delete将不会被执行到，t也就泄露了。虽然我们可以在异常那里把delete给加上，但是在较为大型的项目中，如果对代码进行review来排查这种错误，将会是非常麻烦的一件事，所以为了避免内存泄漏，发明了基于引用技术的智能指针。 智能指针做法 如果不关心std::unique_ptr是什么，这段代码无意是糟糕的，new出来的Test对象根本没有地方被删除，内存泄露了。 但是不必担心，指针已经由std::unique_ptr来管理了，根本不会发生内存泄漏，对象将在离开函数作用域以后被删除。 这就是智能指针的方便之处。 智能指针的基本实现智能指针都通过模板编程来实现，模板是C++的另一大功能，可以使我们更关心实现而不需要关心具体的对象，通过更加抽象的方式来编写程序。 智能指针有两层，里层用来保存对象的指针和引用计数，外层用来调用里层来控制引用计数。 里层的辅助类 外层的控制类 通过重写控制类的拷贝构造函数和赋值运算符重载来更新引用计数。 使用实例 这样我们就有一个简单的智能指针了，不过他还存在一些问题，比如循环引用导致内存泄漏，没有-&gt;和*的操作运算符等。所以我们需要更强大的智能指针来帮助我们。 几种智能指针的介绍标准库提供了几个针对不同方面使用的智能指针，以满足我们的需求。 unique_ptr 只允许一个所有者，除非确信你需要共享该指针，则应该使用shared_ptr。可以转移到新的所有者，但是不会复制和共享。 shared_ptr 采用引用计数的智能指针，如果你想将一个原始指针分配给多个所有者，请使用该智能指针，直到shared_ptr所有者超出了范围或放弃所有权，才会删除原始指针，大小为两个指针，一个用于对象，一个用于引用计数。 weak_ptr 结合shared_ptr使用的特殊智能指针，提供一个或多个shared_ptr实例所拥有的对象的访问，但是不会增加引用计数。如果你想观察某个对象，但是不需要保持活动状态，则可以使用该智能指针。在某些情况下，需要断开shared_ptr实例间的循环引用。 如何正确的选择智能指针智能指针只需要区分需不需要共享使用，如果外部需要使用这个对象，使用shared_ptr，否则就使用unique_ptr进行独占使用。 陷阱和坑 不要使用相同的内置指针来初始化多个智能指针 不要主动回收智能指针内原始指针的内存 不要使用智能指针的get来初始化或者reset另一个智能指针 智能指针管理的资源只会默认删除new分配的内存，如果不是new分配的，则需要使用删除器 "},{"title":"卷积神经网络简述","date":"2018-07-14T16:00:32.000Z","url":"/2018/07/14/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0/","tags":[["Deep Learning","/tags/Deep-Learning/"]],"categories":[["Deep Learning","/categories/Deep-Learning/"]],"content":"前言： 我太菜了… 本来想着写个小例子，结果写到一半发现自己其实根本不会，我还是撸C++去吧。 卷积神经网络(Convolutional Neural Network)是一种前馈神经网络。它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色的表现。 卷积神经网络由一个或多个卷积层和顶端的全连通层组成，同时也包含关联权重和池化层。这一结构可以使得卷积神经网络能够利用输入数据的二维结构。与其他深度学习结构相比，卷积神经网络在图像和声音上能够给出更好的结果，这一模型也可以用反向传播算法进行训练。相比较于其他神经网络、前馈神经网络，卷积神经网络需要考虑的参数更少，使之成为一种颇具吸引力的深度学习结构。 结构卷积层卷积神经网络中每层卷积层由若干卷积单元构成。每个卷积单元的参数都可以由反向传播算法来调整。卷积运算的目的是提取输入的不同特征，第一层卷积可能只提取非常小的特征，更多层的网络只能从低级特征中提取更复杂的特征。 激活函数运行时激活神经网络中某一部分神经元，将激活信息向后传入下一层神经网络。神经网络之所以能解决非线性问题，如语音和图像，本质上就是激活函数加入了非线性的因素，弥补了线性模型的表达力，把“激活的神经元的特征”通过函数保留并映射到下一层。 因为神经网络的数学基础是处处可微，所以选取的激活函数要能保证数据输入与输出也是可微的，介绍四种函数： sigmoid sigmoid函数是传统神经网络中最常用的激活函数之一，它的优点在于，它的输出映射在(0, 1)内，单调连续，非常适合作为输出层，并且求导比较容易，缺点也比较明显，因为软饱和性，一旦落入饱和区，f’(x)就会变得接近0，很容易产生阶梯消失。 tanh tanh函数也具有软饱和性，因为它的输出以0为中心，收敛速度比sigmoid要快，但是仍然无法解决梯度消失问题。 relu relu是目前最受欢迎的激活函数，softplus可以看做是relu的平滑版本。使用线性整流（Rectified Linear Units, ReLU）f(x)=max(0,x)作为这一层神经的激励函数（Activation function）。它可以增强判定函数和整个神经网络的非线性特性，而本身并不会改变卷积层。 dropout 一个神经元将以概率决定是否要被抑制，被抑制的神经元会被暂时认为不属于网络，但是它的权重将会被保留。 池化层池化是卷积神经网络中另外一个非常重要的概念。它实际上是形式的降采样。有多种不同形式的非线性池化函数，而其中“最大池化”是最为常见的。它是将输入的图像划分为若干个矩形区域，对每个子区域输出最大值。直觉上，这种机制能够有效地原因在于，在发现一个特征之后，它的精确位置远不及它和其他特征的相对位置的关系重要。池化层会不断地减小数据的空间大小，因此参数的数量和计算量也会下降，这在一定程度上也控制了过拟合。通常来说，CNN的卷积层之间都会周期性地插入池化层。 池化层通常会分别作用于每个输入的特征并减小其大小。目前最常用形式的池化层是每隔2个元素从图像划分出2x2的区块，然后对每个区块中的4个数取最大值。这将会减少75%的数据量。 除了最大池化之外，池化层也可以使用其他池化函数，例如“平均池化”甚至“L2-范数池化”等。过去，平均池化的使用曾经较为广泛，但是最近由于最大池化在实践中的表现更好，平均池化已经不太常用。 由于池化层过快地减少了数据的大小，目前文献中的趋势是使用较小的池化滤镜，甚至不再使用池化层。 损失函数层损失函数层用于决定训练过程如何来“惩罚”网络的预测结果和真实结果之间的差异，它通常是网络的最后一层。各种不同的损失函数适用于不同类型的任务。例如，Softmax交叉熵损失函数常常被用于在K个类别中选出一个，而Sigmoid交叉熵损失函数常常用于多个独立的二分类问题。欧几里德损失函数常常用于结果取值范围为任意实数的问题。"},{"title":"深度学习笔记","date":"2018-07-14T10:01:01.000Z","url":"/2018/07/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","tags":[["Deepin Learning","/tags/Deepin-Learning/"]],"categories":[["Deepin Learning","/categories/Deepin-Learning/"]],"content":"机器学习，顾名思义当然是用机器来学习。本文完。 上面的话是开玩笑，各位客官不要走… 人工智能人工智能其实不算新名词，在人类历史的长河中，就有过很多关于技艺高超的工匠制造人造人，并赋予智慧。现代的人工智能则始于古典哲学家用机械符号的观点来解释人类思考过程的尝试。 20世纪50年代，人类信心满满的开始了人工智能的征途，但是这趟旅程并不平坦，1973年美英两国政府停止了没有明确目标的人工智能项目的研究。七年后又受到日本政府研究规划的刺激，又恢复了拨款，但是在80年代末再次停止了拨款。人工智能的研究就这样在跌宕起伏中不断的前进。 时光荏苒，人类进入了21世纪，这次人工智能领域终于迎来了新的人生，计算机已经得到了充足的发展，计算能力与日俱增，曾经因为计算能力不足导致无法研究的项目和算法也可以得到重新的验证，当然除了计算能力提升带来的提升，更多的是幕后的工作者不断的改进和完善各种算法，对不同的课题进行长期深度的研究。 人工智能再次进入大众视野是2016年，来自Google公司的AlphaGo成功击败了韩国选手李世石，成为第一个在围棋上战胜人类的人工智能，立下了里程碑。在AlphaGo进行比赛前，人类还自信的认为机器无法在围棋赢得胜利(人类疯狂的奶自己…)。 AlphaGo采用了蒙特卡洛树搜索和两个深度神经网络结合的办法，蒙特卡洛树搜索是基于某种决策过程的启发式搜索算法，两个深度神经网络一个以估值网络来评估大量的选点，一个则以走棋网络来选择落子，在这种设计下，系统可以结合树搜索来长远推断，就像人脑一样评估落点，提高下棋能力。 人工智能、机器学习和深度学习的区别我也对这三个名词产生过疑问，其实很简单： 人工智能： 人工实现的智能 机器学习： 一种人工智能的实现方法 深度学习： 一种机器学习的实现方法 机器学习机器学习是人工智能的一个分支，人工智能的研究历史中有一条以“推理”为重点，到以“知识”为重点，再到以“学习”为重点的自然、清晰的脉络。显然机器学习是是实现人工智能的一条途径，即以机器学习为手段解决人工智能中的问题。 机器学习在近30多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多推论问题属于无程序可循难度，所以部分的机器学习研究是开发容易处理的近似算法。 机器学习的应用机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人等领域。 机器学习的定义机器学习有下面几种定义： 机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习- 中改善具体算法的性能。 机器学习是对能通过经验自动改进的计算机算法的研究。 机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。 机器学习的分类机器学习可以大概分为以下几类： 监督学习：从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。常见的监督学习算法包括回归分析和统计分类。 半监督学习： 介于监督学习与无监督学习之间。 无监督学习： 与监督学习相比，训练集没有人为标注的结果。常见的无监督学习算法有生成对抗网络（GAN）、聚类。 强化学习： 通过观察来学习做成如何的动作。每个动作都会对环境有所影响，学习对象根据观察到的周围环境的反馈来做出判断。 监督学习和无监督学习的差别在于训练数据是否人为标记，他们都有训练集，都有输入输出。 机器学习的算法具体的机器学习算法有： 构造间隔理论分布：聚类分析和模式识别 人工神经网络 决策树 感知器 支持向量机 集成学习AdaBoost 降维与度量学习 聚类 贝叶斯分类器 构造条件概率：回归分析和统计分类 高斯过程回归 线性判别分析 最近邻居法 径向基函数核 通过再生模型构造概率密度函数： 最大期望算法 概率图模型：包括贝叶斯网和Markov随机场 Generative Topographic Mapping 近似推断技术： 马尔可夫链 蒙特卡罗方法 变分法 最优化：大多数以上方法，直接或者间接使用最优化算法。 人工神经网络在机器学习中，目前应用最广泛的是人工神经网络(Artificial Neural Network，ANN)，简称神经网络。是一种模仿生物神经网络的结构和功能的数学模型或计算模型，用于对函数进行估计和近似。神经网络由大量的人工神经元连结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应系统，通俗叫具备学习能力。 人工神经网络的组成现代神经网络是一种非线性统计行数据建模工具，典型的神经网络具有以下三个部分： 结构(Architecture): 指定了网络中的变量和它们的拓扑关系。例如，神经网络中的变量可以是神经元连接的权重（weights）和神经元的激励值（activities of the neurons）。 激励函数(Activity Rule): 大部分神经网络具有一个短时间尺度的动力学规则，来定义神经元如何根据其他神经元的活动来改变自己的激励值。一般激励值依赖于网络中的权重(即该网络中的参数)。 学习规则(Learning Rule): 学习规则指定了网络中的权重如何随着时间推进而调整。这一般被看做是一种长时间尺度的动力学规则。一般情况下，学习规则依赖于神经元的激励值。它也可能依赖于监督者提供的目标值和当前权重的值。例如，用于手写识别的一个神经网络，有一组输入神经元。输入神经元会被输入图像的数据所激发。在激励值被加权并通过一个函数（由网络的设计者确定）后，这些神经元的激励值被传递到其他神经元。这个过程不断重复，直到输出神经元被激发。最后，输出神经元的激励值决定了识别出来的是哪个字母。 在这里我推荐观看3Blue1Brown的三期视频。 深度学习之神经网络的结构 Part 1 ver 2.0 深度学习之梯度下降法 Part 2 ver 0.9 beta 深度学习之反向传播算法 上/下 Part 3 ver 0.9 beta 人工神经网络的基础神经网络的构筑理念是受到生物（人或其他动物）神经网络功能的运作启发而产生的。人工神经网络通常是通过一个基于数学统计学类型的学习方法（Learning Method）得以优化，所以人工神经网络也是数学统计学方法的一种实际应用，通过统计学的标准数学方法我们能够得到大量的可以用函数来表达的局部结构空间，另一方面在人工智能学的人工感知领域，我们通过数学统计学的应用可以来做人工感知方面的决定问题（也就是说通过统计学的方法，人工神经网络能够类似人一样具有简单的决定能力和简单的判断能力），这种方法比起正式的逻辑学推理演算更具有优势。 和其他机器学习方法一样，神经网络已经被用于解决各种各样的问题，例如机器视觉和语音识别。这些问题都是很难被传统基于规则的编程所解决的。 对人类中枢神经系统的观察启发了人工神经网络这个概念。在人工神经网络中，简单的人工节点，称作神经元（neurons），连接在一起形成一个类似生物神经网络的网状结构。 人工神经网络目前没有一个统一的正式定义。不过，具有下列特点的统计模型可以被称作是“神经化”的：具有一组可以被调节的权重，换言之，被学习算法调节的数值参数，并且可以估计输入数据的非线性函数关系这些可调节的权重可以被看做神经元之间的连接强度。人工神经网络与生物神经网络的相似之处在于，它可以集体地、并行地计算函数的各个部分，而不需要描述每一个单元的特定任务。神经网络这个词一般指统计学、认知心理学和人工智能领域使用的模型，而控制中央神经系统的神经网络属于理论神经科学和计算神经科学。 在神经网络的现代软件实现中，被生物学启发的那种方法已经很大程度上被抛弃了，取而代之的是基于统计学和信号处理的更加实用的方法。在一些软件系统中，神经网络或者神经网络的一部分（例如人工神经元）是大型系统中的一个部分。这些系统结合了适应性的和非适应性的元素。虽然这种系统使用的这种更加普遍的方法更适宜解决现实中的问题，但是这和传统的连接主义人工智能已经没有什么关联了。不过它们还有一些共同点：非线性、分布式、并行化，局部性计算以及适应性。从历史的角度讲，神经网络模型的应用标志着二十世纪八十年代后期从高度符号化的人工智能（以用条件规则表达知识的专家系统为代表）向低符号化的机器学习（以用动力系统的参数表达知识为代表）的转变。 神经网络在早期的进展非常缓慢，第一个问题是基本感知器无法解决异或问题，第二个问题是计算机没有足够的能力处理大型神经网络所需要的计算时间,直到计算机具备更强的计算能力前，神经网络的进展都一直很缓慢。 反向传播算法的出现后来出现了关键的的进展: 在1975年由Paul Werbos提出的反向传播算法。该算法解决了异或的问题，还能更普遍的训练多层神经网络。反向传播算法在3Blue1Brown的第二期视频中有讲解,视频中采用了通俗易懂的方式来介绍反向传播算法是如何调整神经元的。 神经网络的又一个关键进展是显卡性能的提升。大家都知道CPU偏向于控制而非计算，这就造成早期处理训练神经网络的代价非常大，使用CPU来训练神经网络的速度非常慢，而现代图形处理器有强大的并行处理能力和可编程流水线，令流处理器也可以处理非图形数据。特别是在面对单指令流多数据流（SIMD）且数据处理的运算量远大于数据调度和传输的需要时，通用图形处理器在性能上大大超越了传统的中央处理器应用程序。现在我们可以轻易的使用Nvidia的CUDA方案或者OpenCL来编写代码，并使用显卡来进行计算。 多层前馈网络一种常见的多层结构的前馈网络（Multilayer Feedforward Network）由三部分组成： 输入层: 众多神经元接受大量非线性的信息，输入的信息被称为输入向量。 隐含层: 是输入层和输出层之间众多神经元和链接组成的各个层面。隐含层可以有一层或多层。隐含层的节点（神经元）数目不定，但数目越多神经网络的非线性越显著，从而神经网络的强健性（robustness）（控制系统在一定结构、大小等的参数摄动下，维持某些性能的特性）更显著。习惯上会选输入节点1.2至1.5倍的节点。 输出层: 在神经元链接中传输、分析、权衡，形成输出结果。输出的信息称为输出向量。 这种网络一般称为感知器（对单隐藏层）或多层感知器（对多隐藏层），神经网络的类型已经演变出很多种，这种分层的结构也并不是对所有的神经网络都适用。 理论性质计算能力多层感知器（MLP）是一个通用的函数逼近器，由Cybenko定理证明。然而，证明不是由所要求的神经元数量或权重来推断的。Hava Siegelmann和Eduardo D. Sontag的工作证明了，一个具有有理数权重值的特定递归结构（与全精度实数权重值相对应）相当于一个具有有限数量的神经元和标准的线性关系的通用图灵机。他们进一步表明，使用无理数权重值会产生一个超图灵机。 容量人工神经网络模型有一个属性，称为“容量”，这大致相当于他们模拟任何函数的能力。它与网络中可以存储的信息量有关，也与复杂性有关。 收敛性模型并不总是收敛到唯一解，因为它取决于一些因素。首先，函数可能存在许多局部极小值，这取决于成本函数和模型。其次，在远离局部最小值时，优化方法可能无法保证收敛。第三，对大量的数据或参数，一些方法变得不切实际。在一般情况下，我们发现，理论保证的收敛不能成为实际应用的一个可靠的指南。 综合统计在目标是创建一个普遍系统的应用程序中，过度训练的问题出现了。这出现在回旋或过度具体的系统中当网络的容量大大超过所需的自由参数。为了避免这个问题，有两个方向：第一个是使用交叉验证和类似的技术来检查过度训练的存在和选择最佳参数如最小化泛化误差。二是使用某种形式的正规化。这是一个在概率化（贝叶斯）框架里出现的概念，其中的正则化可以通过为简单模型选择一个较大的先验概率模型进行；而且在统计学习理论中，其目的是最大限度地减少了两个数量：“风险”和“结构风险”，相当于误差在训练集和由于过度拟合造成的预测误差。 一个小例子现在作为深度学习入门的是手写数字识别，3Blue1Brown的三期视频就是基于此。 通过神经网络来学习如何识别手写数字，本质上就是人类通过算法来分解图像的信息，比如数字9，它可以认为是竖线和圆的组合，输出层是9，则隐含层需要处理竖线和圆，输入层输入的是手写9的全部像素，隐含层就是神经网络的核心，它需要只要竖线和圆又是由什么组成，最后一步步的分解为一个像素，再通过反向传播算法来训练和调节隐含层中的偏置和权值，最后整个网络就可以学习到正确的识别手写数字。 深度学习就是通过人工神经网络来告诉计算机结果是如何产生的，以及如何通过结果来调整网络结构，达到预测和处理未标记的信息。"},{"title":"C plus plus Iterator 笔记","date":"2018-07-09T13:05:12.000Z","url":"/2018/07/09/C-plus-plus-Iterator-%E7%AC%94%E8%AE%B0/","tags":[["C++","/tags/C/"]],"categories":[["C++","/categories/C/"]],"content":"本文记录了咱对迭代器的一些理解 C++ 标准库提供了三种类型组件: 容器 迭代器 算法 容器是指存储某种类型的结构，容器有两种: 顺序容器 (vector、list和string等，是元素的有序集合。) 关联容器 (set、map等，是包含查找元素的键值。 ) 遍历容器的方式之一就是迭代器，迭代器是一种泛型指针，普通指针指向一块内存，迭代器指向容器中的一个位置。STL的每个模板容器中，都定义了一组对应的迭代器类，使用迭代器和算法，就可以访问容器中特定位置的元素，而无需关心元素的类型。 每种容器都定义了一对begin和end的函数，用于返回迭代器。如果容器中有元素的话，begin返回的迭代器指向第一个元素。 上述语句把it初始化为由list的begin返回的迭代器，如果list不为空，it将指向该元素list[0]。 由end操作返回的迭代器指向list的末端元素的下一个，通常指超出末端迭代器(off-the-end-iterator)，表明指向一个不存在的元素，如果容器为空，begin返回的迭代器将和end相同，在使用中，可以通过判断end来检查是否处理完容器种所有的元素。 迭代器类型定义了一些操作来获取迭代器所指向的元素，并允许程序员将迭代器从一个元素移动到另一个元素。 遍历列表： 上面的示例代码是对一个int类型的list进行排序，"},{"title":"在DeepinLinux下使用nVidia CUDA","date":"2018-06-28T03:21:50.000Z","url":"/2018/06/28/%E5%9C%A8DeepinLinux%E4%B8%8B%E4%BD%BF%E7%94%A8nVidia-CUDA/","tags":[["Linux","/tags/Linux/"],["nVidia Cuda","/tags/nVidia-Cuda/"]],"categories":[[" ",""]],"content":"CUDA（Compute Unified Device Architecture，统一计算架构）是由NVIDIA所推出的一种集成技术，是该公司对于GPGPU的正式名称。通过这个技术，用户可利用NVIDIA的GeForce 8以后的GPU和较新的Quadro GPU进行计算。亦是首次可以利用GPU作为C-编译器的开发环境。NVIDIA营销的时候，往往将编译器与架构混合推广，造成混乱。实际上，CUDA可以兼容OpenCL或者自家的C-编译器。无论是CUDA C-语言或是OpenCL，指令最终都会被驱动程序转换成PTX代码，交由显示核心计算。 在论坛上看到有些用户希望在deepin下使用CUDA，但是他们采取的做法往往是手动下载nvidia的二进制文件，直接进行安装。 但是这样会破坏一部分的glx链接，导致卸载的时候无法彻底恢复，结果就是系统因为卸载nvidia驱动而废掉，所以我推荐使用包管理器的方式安装nvidia驱动和cuda相关的东西，尽量不要手动修改。 需要安装的很少，只有五个包，不过会依赖很多nvidia的库，总量还是有一些的。 nvcc是cuda的编译器，它目前只支持g++5，所以还需要安装g++5。 然后，重启一下计算机。 这里有个小栗子，可以用来测试cuda是否能够成功编译和运行 将以下代码保存为 main.cu 编译: 运行: 如果一切顺利，在编译的时候就不会有报错，不过在我的环境下nvcc会有架构被弃用的警告，本着只要不error就算没事的原则，我们无视这条警告即可。 输出结果: "},{"title":"deepin待机后键盘和触摸板无法使用的解决方法","date":"2018-06-25T06:01:22.000Z","url":"/2018/06/25/deepin%E5%BE%85%E6%9C%BA%E5%90%8E%E9%94%AE%E7%9B%98%E5%92%8C%E8%A7%A6%E6%91%B8%E6%9D%BF%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","tags":[["Linux","/tags/Linux/"]],"categories":[[" ",""]],"content":"笔记本一直使用的bumblebee来省电，毕竟我也不想笔记本的电只够从一张桌子移动到另一张桌子，但是今天在调待机唤醒后dde-dock崩溃的问题，我需要切换到私有驱动下，因为笔记本使用bumblebee需要使用acpi的参数，否则会见图形就死。 一切准备就绪以后，我开始调试dde-dock，通过codedump已经知道崩溃在wifi列表为空时访问了first节点，但是当我开始测试修复的代码时，发生了很意外的事情，恢复待机以后键盘和触摸板无法使用了。 虽然之前我也偶尔会用用私有驱动，但是还没遇到过无法键盘和触摸板无法使用的情况。想到论坛好像也有人报了类似的问题，恢复待机以后无wifi和外置键盘无法使用，刚好可以趁这个机会调试一下。 /var/log/Xorg.0.log里看到了大量的synaptics错误，然后该模块被卸载，键盘则是没看到什么信息。 尝试重新modprobe synaptics模块，但是失败了，然后在/etc/modprobe.d/nvidia.conf里看到了几行配置。 似乎是通配出错了，匹配到了键盘和触摸板，然后就无法使用了。刚好deepin 15.6升级了nvidia驱动，所以是现在才会出这个问题。"},{"title":"dreamscene插件开发<等待填坑>","date":"2018-06-05T05:25:40.000Z","url":"/2018/06/05/dreamscene%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/","tags":[["Linux 填坑","/tags/Linux-%E5%A1%AB%E5%9D%91/"]],"categories":[[" ",""]],"content":"本篇会介绍一下deepin-dreamscene的插件机制。 "},{"title":"Dock插件开发<等待填坑>","date":"2018-05-23T05:22:12.000Z","url":"/2018/05/23/Dock%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/","tags":[["Linux","/tags/Linux/"]],"categories":[[" ",""]],"content":"从零构建 dde-dock 的插件本教程将展示一个简单的 dde-dock 插件的开发过程，插件开发者可跟随此步骤为 dde-dock 创造出更多具有丰富功能的插件。 在本教程中，将创建一个可以实时显示用户家目录(~/)使用情况的小工具。 插件的工作原理dde-dock 插件本质是一个按 Qt 插件标准所开发的共享库文件(so)。通过 dde-dock 预定的规范与提供的接口，共同完成 dde-dock 的功能扩展。 准备环境插件的开发环境可以是任意的，只要是符合 Qt 插件规范及 dde-dock 插件规范的共享库文件，都可以被当作 dde-dock 插件载入。下面以 Qt + qmake 为例进行说明： 安装依赖以 Deepin 15.5.1 环境为基础，至少先安装如下的包： dde-dock-dev qt5-qmake qtbase5-dev-tools libqt5core5a libqt5widgets5 pkg-config 基本的项目结构创建必需的项目目录与文件插件名称叫做home_monitor，所以创建以下的目录结构： "},{"title":"Linux的PAM是什么","date":"2018-04-01T12:16:08.000Z","url":"/2018/04/01/Linux%E7%9A%84PAM%E6%98%AF%E4%BB%80%E4%B9%88/","tags":[["Linux","/tags/Linux/"]],"categories":[[" ",""]],"content":"本文会基础的介绍一下PAM是什么，让你能够回答PAM是什么、PAM有什么用、如何根据需求自己开发PAM模块。 PAM是什么PAM即可插拔认证模块。它提供了一个所有服务的中心验证机制，适用于普通登录、ssh登录等需要进行身份认证的系统中。 为什么使用PAM为了安全起见，计算机只能给通过授权的用户进行使用，在创建用户时，密码会被加密保存在/etc/passwd中,在用户登录时，重新计算密码，然后在/etc/passwd中进行对比。 除了上面这种，还有其他方式的验证，比如现在经常使用的指纹认证，其核心思想都是检查内容是否匹配。但是这些方案都有一些通病，那就是需要随着应用程序一起编译来使用，如果认证系统有问题，或者更新了算法，就需要重新编译才能使用。 鉴于以上原因，人们开始寻找一种更佳的替代方案：一方面，将鉴别功能从应用中独立出来，单独进行模块化设计，实现和维护；另一方面，为这些鉴别模块建立标准 API，以便各应用程序能方便的使用它们提供的各种功能；同时，鉴别机制对其上层用户（包括应用程序和最终用户）是透明的。 PAM是如何工作的 PAM采用了分层的模块式开发，提供了四种类型的模块: 认证管理 账号管理 会话管理 口令管理 这四个接口就可以满足用户的认证和管理。一个模块可以同时属于多种类型，只需实现对应的函数就可以。 目前PAM的实现有以下三种： Linux-PAM: Linux-PAM 涵盖了本文中讨论的所有 PAM。在任何一个 Linux 平台中的 PAM 的主要结构都类似于 Linux-PAM 版本。 OpenPAM: OpenPAM 是由 NAI 实验室的 Dag-Erling Smorgrav 开发的另一个 PAM 实现，属于 DARPA-CHATS 研究项目。由于它是开源的，因此它主要由 FreeBSD、NetBSD 及应用程序（加上 Mac OS X）使用。 Java™ PAM 或 JPam: PAM 主要是支持 Linux 和 UNIX 的标准验证模块。JPam 将 Java 部分与普通 PAM 联系了起来。JPam 允许基于 Java 的应用程序使用 PAM 模块或工具（如 auth、account、passwd、session 等）。它提供了 JAAS 和直接 API，并且支持大多数 Unix OS 和架构。 虽然有不同的PAM实现，但是主要功能都是类似的，完成用户的验证。 想要了解更多，可查看IBM的文档库。深入 Linux PAM 体系结构 如何自己开发PAM模块PAM模块使用一个pam_handle类型的结构当做句柄，也是唯一一个PAM和程序进行通信的结构。 首先在编写的服务模块的源程序里要包含下列头文件： PAM模块是一个个的so动态库。PAM会通过dlopen来装载这些so。四个模块分别需要实现对应的方法，PAM会根据配置文件来调用这些方法。 每个PAM模块的认证程序都以pam_start开始，以pam_end结束。PAM还提供了pam_get_item和pam_set_item共享有关认证会话的某些公共信息，例如用户名、服务名和密码。应用程序在调用了pam_start以后可以用这些APIs来改变状态信息。实际工作的函数有6个： 模块类型 函数 功能 认证管理 PAM_EXTERN int pam_sm_authenticate(pam_handle_t *pamh, int flags, int argc, const char **argv) 认证用户 认证管理 PAM_EXTERN int pam_sm_setcred(pam_handle_t *pamh, int flags, int argc, const char **argv) 设置用户证书 账号管理 PAM_EXTERN int pam_sm_acct_mgmt(pam_handle_t *pamh, int flags, int argc, const char **argv) 账号管理 会话管理 PAM_EXTERN int pam_sm_open_session(pam_handle_t *pamh, int flags, int argc, const char **argv) 打开会话 会话管理 PAM_EXTERN int pam_sm_close_session(pam_handle_t *pamh, int flags, int argc, const char **argv) 关闭会话 口令管理 PAM_EXTERN int pam_sm_chauthtok(pam_handle_t *pamh, int flags, int argc, const char **argv) 设置口令 同一个模块可以同时支持不同的类型，可以一个模块全部实现这些方法，也可以实现部分。PAM自带的pam_unix.so就是支持四种类型。 在函数内进行详细的操作，最后返回结果，即可完成整个验证流程。 配置PAMPAM的配置通常在/etc/pam.d/下。 模块将按照在配置文件中列出的顺序被调用，这取决于每个条目允许的 Control_flag 的值。Control_flag 值包括： Required：堆栈中的所有 Required 模块必须看作一个成功的结果。如果一个或多个 Required 模块失败，则实现堆栈中的所有 Required 模块，但是将返回第一个错误。 Sufficient：如果标记为 sufficient 的模块成功并且先前没有 Required 或 sufficient 模块失败，则忽略堆栈中的所有其余模块并返回成功。 Optional：如果堆栈中没有一个模块是 required 并且没有任何一个 sufficient 模块成功，则服务/应用程序至少要有一个 optional 模块成功。 在程序中使用PAM进行验证 开发PAM验证模块 编译: 还需要修改pam的配置，来加载这个so。编辑/etc/pam.d/common-auth 这里的success的值需要根据实际情况来调整，必须是所有里面的最大值。 使用模块进行验证 编译测试一下: 输出为： 总结基于PAM认证体系，我们可以根据自己的需求任意的扩展linux账户，linux下的pbis-open，就是基于PAM扩展出来的一个AD域登录模块，它提供了一个pam_lsass.so的文件，来进行账户的验证。我们也可以自己设计一套认证流程，只需要满足上面的接口要求就可以。 提供机制，而非策略 "},{"title":"重构dde-session-ui","date":"2018-03-11T11:48:01.000Z","url":"/2018/03/11/%E9%87%8D%E6%9E%84dde-session-ui/","tags":[["Linux","/tags/Linux/"]],"categories":[[" ",""]],"content":"dde-session-ui里面包含了很多项目，是一个集合，但是其中的代码缺少合理的维护，以至于已经到了必须重构才能继续开发和维护，在支持AD域登录的时候，如果强制加上功能，代码会变得更加糟糕，所以和石博文一块重构了其中非常重要的UserWidget。 重构前的设计重构前的dde-lock和lightdm-deepin-greeter是非常混乱的，处理逻辑都混杂在一块，虽然能看出有基本的结构，但是整体并未解耦。 重构后的设计 基于User类的处理 UserWidget负责提供对用户的处理，暴露出基本的currentUser和LogindUsers。 Lock和Greeter的Manager从UserWidget、SessionWidget中获取用户和用户的会话。 Manager只负责控件的位置和用户的验证。 背景修改为Manager提供模糊的壁纸，FullBackground只提供绘制。 重构以后用了大概原代码的1/3，启动速度也快了，感觉世界充满了美好… 就是重构历程太辛苦… 本次也发现了很多自身的问题，基础并没有学好，很多地方都可以使用更好的处理方式【就是管不住这手…】"},{"title":"使用DTK开发","date":"2018-01-12T11:05:26.000Z","url":"/2018/01/12/%E4%BD%BF%E7%94%A8DTK%E5%BC%80%E5%8F%91/","tags":[["Linux DTK","/tags/Linux-DTK/"]],"categories":[[" ",""]],"content":"在阅读本篇文章之前，你需要掌握基本的Qt/C++开发知识。 注意：本篇文章基于Deepin平台，其他平台请自行补充依赖关系。 先安装DTK的依赖关系。 新建Qt项目，编辑pro文件，添加项目依赖。 DTK目前有两个组件，一个是提供库功能的core，一个是提供控件的widget。 修改main.cpp,删除QApplication的相关内容，改为DApplication。 注意： 使用DTK的组件，需要使用DTK的宏,根据使用的文件来选择对应的宏。 DTK使用了deepin自己的qt插件，需要在DApplication前调用。 DApplication中提供了很多方法来设置程序的各种信息，具体请看头文件的定义。 主窗口由DMainWindow提供，新建类，然后添加DMainWindow的头文件和DTKWIDGET的宏。 然后修改继承关系，改为继承DMainWindow。DMainWindow提供了一些我们封装的方法。目前为止，该程序的界面已经符合Deepin程序的风格了，我们封装了一些其他控件，使其样式符合我们的风格，如果要在其他Qt程序中使用，也是同样的步骤，载入Qt插件，添加对应的头文件和DTK的宏。"},{"title":"解决IntelliJ IDEA界面瞎眼","date":"2017-12-25T14:22:25.000Z","url":"/2017/12/25/%E8%A7%A3%E5%86%B3IntelliJ-IDEA%E7%95%8C%E9%9D%A2%E7%9E%8E%E7%9C%BC/","tags":[["Linux","/tags/Linux/"]],"categories":[[" ",""]],"content":"今天在逛深度论坛的时候，无意间看到了有个回复，是处理IEDA字体很挫的，试了一下，效果非常棒。 我之前也试了些网上的办法，都没有解决，字体挫的根本看不了，被逼无奈跑到windows下写MOD了。 原文链接 在/etc/profile.d/新建一个文件，用来设置java的环境变量: 然后注销再登录，就可以看到效果了。 其实这个解决办法在arch的wiki上有，只不过似乎是我写错了吧，反正是没生效，按照这种方法是可以的，就这么用吧。非常感觉@ihipop。"},{"title":"修复Archlinux的Grub","date":"2017-12-18T09:44:55.000Z","url":"/2017/12/18/%E4%BF%AE%E5%A4%8DArchlinux%E7%9A%84Grub/","tags":[["Linux","/tags/Linux/"]],"categories":[[" ",""]],"content":"又双叒叕不知道怎么搞的，就把arch的grub给弄坏了，但是在重新安装grub的时候，提示了这么一个错误: 诶不对啊，boot分区还有800M呢，怎么这么快没空间了，根目录也有52G呢，于是谷歌了一把，找到了解决办法. 新式 efivarfs (EFI VARiable FileSystem) 接口 (CONFIG_EFIVAR_FS) - 由位于 /sys/firmware/efi/efivars 的 efivarfs 内核模块挂载使用 - 老式 sysfs-efivars 接口的替代品，不限制变量数据大小，支持 UEFI Secure Boot 变量并被上游推荐使用。在3.8版的内核中引入，新的 efivarfs 模块在3.10版内核中从旧的 efivars 内核模块中分离。 删掉dump文件，就可以正常安装了【有点迷，不应该啊。 参考资料 : Unified_Extensible_Firmware_Interface"},{"title":"解决NVIDIA重新启动以后系统冻结","date":"2017-09-01T17:01:47.000Z","url":"/2017/09/01/%E8%A7%A3%E5%86%B3NVIDIA%E9%87%8D%E6%96%B0%E5%90%AF%E5%8A%A8%E4%BB%A5%E5%90%8E%E7%B3%BB%E7%BB%9F%E5%86%BB%E7%BB%93/","tags":[["linux","/tags/linux/"]],"categories":[[" ",""]],"content":"分期买了一台神舟 Z6-kp5s1，配置还不错，够用三年了，但是在linux下使用bumblebee的时候，发生了问题，折腾了好久，现在把解决方法写出来。 先说一下问题吧，正常安装bumblebee、bbswitch和nvidia驱动，重新启动系统以后，系统出现冻结，没有任何的输入输出，没有任何日志产生。问题似乎是固件错误，详情查看讨论和Linux的bug讨论。 解决方法是看的Witiko的博客，通过给内核传递参数来防止系统出现冻结。修改/etc/default/grub,在文件底部追加以下内容： 如果不放心，请先禁用登录管理器，防止开机就出现冻结，然后尝试手动启动登录管理器。在tty登录，然后执行： 如果一切正常，你将会看到图形，并且lspci -v中能看到nvidia已经被禁用，然后使用提供的测试方法进行测试，可以看到nvidia被启用，关闭测试成功，nvidia被禁用。 提供一下我关闭nvidia以后的使用和续航时间吧。亮度调节为50%，cpu设置为powersave，运行了一下程序： telegram chrome dde-file-manager vs code meow 若干ss client 还有一大堆乱七八糟的服务，懒得写了 从14:35开始断电测试，到17:17还有23%的电量。"},{"title":"我的代理折腾方案","date":"2017-08-31T20:43:48.000Z","url":"/2017/08/31/%E6%88%91%E7%9A%84%E4%BB%A3%E7%90%86%E6%8A%98%E8%85%BE%E6%96%B9%E6%A1%88/","tags":[["linux","/tags/linux/"]],"categories":[[" ",""]],"content":"最近在准备做新的代理设置界面，然后想到自己也改改代理的配置，好方便的用在新的设置上。 我以前的旧方案是： privoxy –&gt; nginx –&gt; 多个ss客户端 ==== 多个ss服务端 privoxy用来将socks转成http，nginx是用来多个ss负载均衡。 这个方案虽然有点麻烦，但是用起来还是很吼的。 但是我们改了控制中心对代理的设置，在程序前面加上了proxychains。刚好可以和我的privoxy在作用上冲突了。但是其实还有一些其他问题，我是比较懒的人，跳过大陆ip和局域网对我来说是有很大帮助的，这样我就可以设置一个全局代理，而不需要给每个程序单独设置。 以前肥猫给我介绍过一些方法，当初我弄的时候，还是太图样，总是不能好好的稳定工作，所以暂时放弃了全局代理的方案。provixy其实是可以做这样的事，但是好麻烦，要自己添加很多规则，gfwlist是可以转成它支持的action，但是自己再添加的话，很麻烦。【而我是根比较懒的竹子 今天把provixy给撤下来了，换上以前用的meow，是用go写的，作用也是转成http，但是它支持的方案比较多，可以直接添加ss，也可以正向代理。当初不用它的原因是我想随机使用一个代理，当时电信和我过不去，一个端口用久了，就封我一天，害得我早上到公司了，先远程到服务器改端口，后来又觉得麻烦，直接开了5个端口，每天改本机，再后来就想随机使用了… 【还有次把我的ssh端口封了一天… 现在的话，就是变成了这个结构： meow –&gt; nginx –&gt; 多个ss客户端 ==== 多个ss服务端 nginx还是代替meow做负载均衡，meow的工作就变成了转成http代理和黑白名单。 虽然不需要新的控制中心的代理方案，现在这套就工作的很好了，但是没有它，我就不会再折腾新的【笑哭"},{"title":"开发topbar中的技术问题","date":"2017-08-23T08:54:56.000Z","url":"/2017/08/23/%E5%BC%80%E5%8F%91topbar%E4%B8%AD%E7%9A%84%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98/","categories":[[" ",""]],"content":"这里记录了开发topbar中遇到的坑和一些问题。 使用Qt提供的qxcb方法注册阴影为dock类型，反而处于DESKTOP和NORMAL之间。其实当初并不是想设置为DOCK类型的，因为这样阴影也会在窗口上方，我希望的是阴影在普通程序下方，在桌面上方。今天曹哥来讲窗管的一些坑，讲到窗管是如何控制窗口的，我的阴影其实是被Qt注册成_NET_WM_STATE_BELOW了。这里可以看到一些type的介绍。 在_NET_WM_STATE中一共有这么几个类型： 如果程序被注册成_NET_WM_STATE_BELOW，则会被放置在DESKTOP之上的一层。不是很清楚Qt是出于什么策略，才把我的阴影注册为这个状态，反而是刚好满足了我的需求。 这要多谢曹哥了，我才终于明白了为什么会这样，以及以后如何正确的设置type。 "},{"title":"TKL主题优化 -<转>","date":"2017-08-20T05:05:54.000Z","url":"/2017/08/20/TKL%E4%B8%BB%E9%A2%98%E4%BC%98%E5%8C%96-%E8%BD%AC/","tags":[["Hexo","/tags/Hexo/"]],"categories":[[" ",""]],"content":" 这个主题确实挺好的，我也魔改了一部分来达成自己的目的，添加tags是看的这篇文章。"},{"title":"debug了两天，只删了一行代码","date":"2017-08-16T18:25:39.000Z","url":"/2017/08/16/debug%E4%BA%86%E4%B8%A4%E5%A4%A9%EF%BC%8C%E5%8F%AA%E5%88%A0%E4%BA%86%E4%B8%80%E8%A1%8C%E4%BB%A3%E7%A0%81/","categories":[[" ",""]],"content":"前言： 项目一定要留一些文档！！ 修bug前一定要知道所有的流程！！！ 这两天一直在修一个用户切换的bug，众所周知，deepin的多用户切换一直都不是正常工作的，确切来说是压根没有正常工作，还好用户不是经常切换，不然早就收到一大波的报告了。 dde-session-ui项目中包含了以下软件： dde-lock dde-shutdown dde-osd lightdm-deepin-greeter dde-switchtogreeter dde-suspend-dialog dde-warning-dialog dde-welcome dde-wm-chooser dde-lowpower dde-offline-upgrader 大部分项目根据名字就可以知道是做什么的，这是一个软件组的集合。而dde-lock和lightdm-deepin-greeter二者有大量重复的功能和代码，这是它俩的工作性质决定的。 lightdm-deepin-greeter: display-manager启动的实体，登录的界面是它负责的。 dde-lock： 用户层面的屏幕锁定，基于我们的设计，和lightdm-deepin-greeter是大致相同的布局。 而且都包含了用户密码的验证，用户的切换，但是二者工作的层面是不同的，为了方便切换，就有了dde-switchtogreeter，用来协调二者的工作，只需要提供用户名就可以切换。 然而，虽然这样的想法是很好的，可是当初并没有人写文档，随着人员的变动，现在公司应该没有一个人是比较完整了解整个的工作流程了，用户切换的bug也就这样被留下来了。 上次修复用户切换的问题，是发现登录以后lightdm-deepin-greeter没有退出，由于不是很清楚linux的登录流程，再加上代码中有不工作的退出代码，当时就改好了退出的问题，这样就引入了第二个问题，而这个问题，就导致了两天三个人在一直查找问题所在。 这次的问题是发现一直切换greeter，会导致Xorg一直在开新的display，这就很奇怪了，正常来说是不会一直创建才对。 最开始以为是dde-switchtogreeter的问题，毕竟切换是它在做，dde-switchtogreeter是单文件的c代码，代码没有任何的说明，真的是为切换而生，我从main函数开始自己走了好几遍的流程，一边看着d-feet的数据来验证，然而只发现了一个小问题，整个代码是没啥问题的。 最后在后端大佬的帮助下，知道了display-manager会自己退掉greeter，不需要自己退，然后我就想起来了以前改的地方，赶紧把退出代码删掉，重新编译，问题得到了解决。 如果我知道display-manager的工作流程，也许这个问题就不会拖两天了。"},{"title":"正常的流程在界面上却是bug","date":"2017-08-15T07:43:43.000Z","url":"/2017/08/15/%E6%AD%A3%E5%B8%B8%E7%9A%84%E6%B5%81%E7%A8%8B%E5%9C%A8%E7%95%8C%E9%9D%A2%E4%B8%8A%E5%8D%B4%E6%98%AFbug/","categories":[[" ",""]],"content":"排查了一天，最后终于确认了流程，知道了问题所在，不得不说，dde-session-ui这个项目太需要一个文档了，要把工作流程写的非常详细才可以。 上午收到了一条新任务，是龙芯上新安装的系统需要输入两次密码才可以登录，没有错误提示。近期并没有什么太大的改动，无非是给龙芯也用上了简单重构过的dde-session-ui，怎么会导致这样的问题。 由于是新安装的系统才会发生，而且是现象一旦发生，就无法重现，这让我头有点大，怎么会有这样的神奇的事情，而且日志中很正常，没有收到message导致密码框被清空。我提交了一个添加了更多日志的，然后重装的龙芯的系统(龙芯重装一次要半个小时)，等重装完了，切换到tty去安装这个包，然后重启lightdm，让我输入密码回车以后，密码消失，我赶紧去看日志，但是日志中并没有我的输出，回车以后肯定会有的一行输出也没有(内心OS：What the fuck is that？) 我又回去看验证的流程，并没有发现有什么不对的地方，而且是近期才有的，我在自己电脑上使用了龙芯的编译参数，打了一个deb包，并没有发生和龙芯一样的情况（这里并不需要，既然是新安装的系统才会发生，在旧系统上是无法重现的）。 再然后我暂时没有管这个，先去修其他bug了。忙完以后，我去问了一下其他大佬，大佬给我提了几条让我去看看，是不是起了两个lightdm-deepin-greeter进程，确认一下使用的二进制是不是你加了log的。（然后我又重装龙芯了），之后确认了是我的二进制，也没有起两个进程。但是ps中有两行输出，我以为是起了两个，就让后端大佬看了一下，后端大佬告诉我说一个是shell的进程，一个是本体，还是只有一个进程存在的。我彻底懵逼了，然后后端大佬告诉我，是不是greeter进程写入什么了，之后的验证中内容已经存在，所以就不会重现了。 其实这个我也想过，但是没考虑太深，greeter并没有操作文件，但是大佬这么一说，我想到有一些dbus的调用，是有写入文件的，然后我把/var/lib/lightdm/lightdm-deepin-greeter目录给删除了，完美重现。 我的天啊，排查了快一天，居然是这个目录在新装的系统上没有，所以回车登录以后收到了来自dbus的switchToUser，界面重启导致的内容消失，根本不是收到了Message才被清空的，所以我的log也没有打印出来。 知道了如何重现，可是要怎么修复呢，似乎在greeter上并不能修复，只能去改dde-daemon中LockService，如果文件不存在，就不要发送userChanged的信号。（流程是读取这个文件的信息，和传入的参数进行对比，但是文件是空的，所以被认为不是同一个账户，就发送了信号，也导致了界面上重启，以后无法重现是因为里面已经有内容了）。 就这样，一个流程很正确，但是表现到界面上时就成了一个bug的问题被解决了。写下这篇内容是为了记录我如何解决对我来说很棘手的问题，其实这个问题并不是很困难，但是对整个工作的流程不是很熟悉，导致浪费了大量的时间在非关键点处理，有空要写一些文档了。"},{"title":"在deepin上使用dnsmasq来解决dns解析缓慢","date":"2017-08-11T14:07:26.000Z","url":"/2017/08/11/%E5%9C%A8deepin%E4%B8%8A%E4%BD%BF%E7%94%A8dnsmasq%E6%9D%A5%E8%A7%A3%E5%86%B3dns%E8%A7%A3%E6%9E%90%E7%BC%93%E6%85%A2/","categories":[[" ",""]],"content":"其实这个问题影响并不是很大，只是稍微的增加一点点访问速度，缓存这东西有利有弊。 在写完这篇文章以后，我就不用dnsmasq了，现在用的是github上的Pcap_DNSProxy。用来防止dns污染的。 根据 中回答者提供的信息来看，linux发行版是不提供dns解析缓存的，上面提到的nscd也不在deepin的预装列表中，所以我们只能自己动手丰衣足食了。 首先安装口碑较好的dnsmasq，来为我们提供dns缓存。 如果是deepin最新的2015.4.1版本中安装，安装结束会提醒一个错误，这个错误的解决办法来自.这个错误似乎是因为/usr/share/dns/root.ds文件更新后结构导致的错误。 编辑/etc/init.d/dnsmasq，并找到 修改为 当错误解决以后，我们手动重启一下dnsmasq的systemd服务。 deepin的/etc/resolv.conf来自/etc/NetworkManager/resolv.conf.是一个软连接。我采取的行为是删除这个文件，重新创建。 然后写入本地地址当做dns地址。 dnsmasq是一个本地的dns和dhcp服务器，当我们在上面成功启动dnsmasq以后，个人系统中就已经在提供dns服务了，所以本机使用回环地址来表明dns服务器就是本机，所有的dns查询都会发送到本机的dnsmasq中。 如果需要额外添加dns服务器，做法来自. 创建一个 /etc/resolv.dnsmasq.conf，写入其他dns服务器的地址。 然后编辑 /etc/dnsmasq.conf,找到resolv-file字段，改为 然后重启dnsmasq。 验证的话通过dig命令。 通过执行两次来判断，Query time在第二次查询是为0 msec。"},{"title":"PPA","date":"2017-07-24T16:07:50.000Z","url":"/2017/07/24/PPA/","categories":[[" ",""]],"content":"也许需要安装dirmngr maybe you need install dirmngr 追加内容到/etc/apt/sources.list Append content to /etc/apt/sources.list 导入key import key "},{"title":"topbar PPA","date":"2017-07-20T13:37:51.000Z","url":"/2017/07/20/topbar-PPA/","categories":[[" ",""]],"content":"自己搭了一个仓库，提供deepin-topbar及相关依赖的包。 I created a repository,provide deepin-topbar and dependencies. 也许需要安装dirmngr maybe you need install dirmngr 追加内容到/etc/apt/sources.listAppend content to /etc/apt/sources.list 导入keyimport key 刷新列表，进行安装then, refresh list and install "},{"title":"webhook","date":"2017-07-14T02:52:20.000Z","url":"/2017/07/14/webhook/","tags":[["linux","/tags/linux/"]],"categories":[[" ",""]],"content":"blog现在是用hexo，放在自己的code网站上。 code是用无闻大大的gogs搭建的，跑在台式机的docker中，本机跑了很多docker服务，有hexo，有aria2c，有gogs，还有个webserver caddy。 caddy这东西还是基友 不爱写博客的mioto推荐给我的，之前我一直是用nginx的，那配置文件太复杂了，根本玩不来。 写一篇文章，会先提交到code，然后触发webhook，caddy会拉取code中的文章，由于是静态的，所以不需要处理其他的，只需要拉取最新的就可以了。 caddy的配置 gogs上只需要创建一个webhook，地址填写成caddy中的hook地址，加密填写hook后的xxx即可，加密自己设置。 然后就可以提交了。 提交会触发push操作，gogs会根据设置的webhook中的规则，执行和push相关的webhook，webhook会向指定的url发送POST操作，发送的内容中包含了相关信息，caddy会根据相关信息，来处理webhook，执行你规定的操作。"},{"title":"SAOUTILS","date":"2017-07-04T06:20:00.000Z","url":"/2017/07/04/SAOUTILS/","tags":[["linux","/tags/linux/"]],"categories":[[" ",""]],"content":"鼠标手势还没想好要怎么实现，流程无法完全确认，这项稍后再做。 主界面有两层构成，半透明全屏黑色背景和菜单。 菜单较为复杂，除了左边是一个大面板，其他部分全部都可以使用一种方式实现。使用Qt的QAbstractItemDelegate、QListView来做列表和界面绘制。 右边则是无限展开的菜单。 每层菜单只是用一个对象，和topbar dock的popup window一样。点击每层菜单的时候，计算下一项要显示的位置。 主界面应该是只有左右两部分，除了左边的大面板，右侧全部都是相同结构的菜单，只不过在功能上略有不同。 点击的时候，所有菜单对鼠标点击的地点进行坐标计算，如果在鼠标右侧，则隐藏。如果要显示的菜单是自己，不隐藏。点击时开始timer，松开时停止，timeout以后显示选项。 保持最后一个菜单在最中间的位置，主界面向左或向右用动画移动固定长度。"},{"title":"Topbar","date":"2017-06-26T02:32:35.000Z","url":"/2017/06/26/Topbar/","tags":[["linux","/tags/linux/"]],"categories":[[" ",""]],"content":" topbar的架构参考的是dde-dock，就是一个精简的dock，只有一个方向，一个位置，没有右键菜单，只有插件类型。 计划是用来支持各种各样的方便的插件，比如： 活动窗口指示器 多媒体控制器 电源控制 时间控制 计划要完成有： shadowsocks vpn控制器 系统资源监视器 剩下的计划待完成的插件由于各种原因，开发比较难，还需要学习一部分知识才可以完成。"},{"title":"ArchLinux运行steam出现缺少LibGL--steam libGL error: failed to load driver: swrast","date":"2016-07-15T07:18:53.000Z","url":"/2016/07/15/ArchLinux%E8%BF%90%E8%A1%8Csteam%E5%87%BA%E7%8E%B0%E7%BC%BA%E5%B0%91LibGL-steam-libGL-error-failed-to-load-driver-swrast/","tags":[["实验室","/tags/%E5%AE%9E%E9%AA%8C%E5%AE%A4/"]],"categories":[[" ",""]],"content":"其实arch的wiki已经提到了，而且这个问题是比较常见的，只需要删除steam的库就行。 wiki原文链接 删除运行库运行此命令，删除在issues上已知的运行库问题: 如果上面的命令不工作，则再次运行上面的命令，然后运行此命令。 "},{"title":"docker-hexo","date":"2016-07-15T04:53:24.000Z","url":"/2016/07/15/docker-hexo/","tags":[["实验室","/tags/%E5%AE%9E%E9%AA%8C%E5%AE%A4/"]],"categories":[[" ",""]],"content":"引用一下基友的话 最开始接触 Hexo 的时候是在 Windows 下, 安装过程还算顺利, 因此在初期还整理了6篇关于 Hexo 博客的搭建教程. 后来转投 Linux 大法, 期间重装电脑无数次, 每一次安装 Hexo 所需要的 nodejs, 和各种插件的时候都是闹心的过程, 玩的多了自然就熟了, Linux 下的安装基本没问题了. 然后入职公司, 公司配了 Mac Pro 又需要安装 Nodejs, 以及各种插件, 人傻搞不定啊.., 晚上迷迷糊糊的还 rm -rf /usr/bin 了.., 所以决定放弃在实体机安装 Nodejs 的想法转战到了 Docker. 来自mashiro.io 他后来更新了一下dockerfile，他觉得以前的思路是错的，现在他要把hexo封装进docker当做工具，又写了几个alias。安装docker，然后pull镜像 pull镜像以后，写入alias，将docker-hexo当做本地工具。 然后执行一下命令 把以上内容写进rc文件，我是用zsh的，所以写入~/.zshrc。 接下来基本演示一下使用方式。 "},{"title":"docker-aria2c","date":"2016-05-31T22:43:54.000Z","url":"/2016/05/31/docker-aria2c/","tags":[["实验室","/tags/%E5%AE%9E%E9%AA%8C%E5%AE%A4/"]],"categories":[[" ",""]],"content":"该项目是将aria2c封装进docker并提供服务。 下载好镜像，然后保存一份运行 打开浏览器，访问输入 注意，暂时还无法处理文件的所有权，目前下载好的文件归属root。"},{"title":"aria2配置","date":"2016-05-25T23:56:00.000Z","url":"/2016/05/25/aria2%E9%85%8D%E7%BD%AE/","tags":[["教程","/tags/%E6%95%99%E7%A8%8B/"]],"categories":[[" ",""]],"content":"安装好aria2，然后执行一下内容 注意以上内容需要把用户名字更改成自己的 在用户目录新建三个文件 ~/.config/aria2.conf 里面需要填写以下内容，其他两个文件保持空。 启动服务 浏览器打开：将服务器地址改成 然后应该页面的右上角就显示网速了。"},{"title":"linux下安装vmware及archlinux的安装和配置","date":"2016-04-10T17:02:51.000Z","url":"/2016/04/10/linux%E4%B8%8B%E5%AE%89%E8%A3%85vmware%E5%8F%8Aarchlinux%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/","tags":[["教程","/tags/%E6%95%99%E7%A8%8B/"]],"categories":[[" ",""]],"content":"视频中给出了vmware的下载地址和安装过程，系统的下载我也会演示一遍。这篇教程会一篇完成，从安装到配置和美化，顺便也总结一下我的成果。由于我已经安装过一次vmware了，所以有个脚本的地方没有出现，输入界面上的提示信息即可。宿舍太乱，所以就没有录麦克风，操作我会尽量慢一些，然后打字讲述。这次大更。。gtk主题还没更新上来，所以界面好丑。 = =。安装完成以后安装源里面的vmware-patch。"},{"title":"Archlinux 添加漂亮的字体","date":"2016-04-08T16:54:26.000Z","url":"/2016/04/08/font-config/","tags":[["教程","/tags/%E6%95%99%E7%A8%8B/"]],"categories":[[" ",""]],"content":"该教程不能保证适用于所有人的情况。字体也不是配置，而是补充了字体。使用的是第三方的源。 打开/etc/pacman.conf文件，添加以下内容到最底部。 执行安装命令: 如果有遇到错误，可以手动添加hosts： 会出现很多冲突，选择Y，然后安装。如果中断了，重新执行安装命令。 来自：如何给任意一款 Linux 发行版添加漂亮的字体-桌面应用|Linux.中国-开源社区"},{"title":"My Life","date":"2016-03-25T11:56:08.000Z","url":"/2016/03/25/my-life/","tags":[["日常","/tags/%E6%97%A5%E5%B8%B8/"]],"categories":[[" ",""]],"content":"这是我用markdown写的第一篇文章(水文)，先来个自我介绍吧，我是小竹，对没错，是小竹，不是竹子，不是竹酱，更不是竹基。 我玩linux应该有五六年了吧，初二的时候接触的，不过很多年都保持在换各种发行版上，并没有真正意义的玩。上了大学以后，接触的更多了，玩的也更嗨了。现在也用上arch+btrfs+uefi了，各种叼炸天。irc里面也经常学习【看别人装逼。依旧是英语渣渣，数学渣渣，看到win32api，我直接放弃win编程了，我的智商也就玩玩wpf了。下面就贴几张我的日常截图。 My Computer info "},{"title":"标题","date":"2016-03-25T00:00:00.000Z","url":"/2016/03/25/page/","tags":[["模板","/tags/%E6%A8%A1%E6%9D%BF/"]],"categories":[[" ",""]],"content":""},{"title":"Comment Policy guidelines 评论政策","date":"2018-07-09T09:59:09.000Z","url":"/guidelines.html","categories":[[" ",""]],"content":"很简单，平和交流。"},{"date":"2021-03-04T07:40:49.481Z","url":"/test.html","categories":[[" ",""]],"content":" Page Title "},{"title":"圣人忘情，最下不及于情，情之所钟，正在我辈。","date":"2017-08-18T10:07:58.000Z","url":"/about/index.html","categories":[[" ",""]],"content":"不断追赶，缩小差距，这是我的人生写照。 教育情况 2011年 – 2014年 河南省禹州市职业中专计算机专业 2014年 – 2016年 河南省商丘工学院软件技术专业 工作经历 2016年9月 – 至今 武汉统信科技(原武汉深之度科技有限公司),负责开发deepin linux的桌面环境和相关软件。 个人技能 Qt/C++ Go (入门) TypeScript (入门) Rust (入门) 个人项目 topbar 在DDE桌面上实现类似于苹果的顶栏，支持系统托盘 视频壁纸 在DDE桌面上实现置低窗口播放视频 已归档 konachan爬虫 满足个人壁纸爱好的爬虫，使用Go编写 Mail Telegram GPG Fingerprint Download Public Key"},{"title":"Categories","date":"2021-03-04T07:40:49.421Z","url":"/categories/index.html","categories":[[" ",""]]},{"title":"友链","date":"2021-03-04T07:40:49.421Z","url":"/friends/index.html","categories":[[" ",""]]},{"date":"2021-03-04T07:40:49.481Z","url":"/laopo/index.html","categories":[[" ",""]],"content":" 送给我最爱的媳妇 向下滚动 这是谁？ 我想认识认识你 n(*≧▽≦*)n 媳妇你真好看！ 我最喜欢你了！ "},{"date":"2021-03-04T07:40:49.481Z","url":"/laopo/main.css","categories":[[" ",""]],"content":"section { height: 100vh; width: 100vw; color: #fff; line-height: 100vh; text-align: center; font-size: 5vh; } .short-section { height: 0vh; width: 100vw; color: #fff; line-height: 100vh; text-align: center; font-size: 5vh; } .g-word { background: rgba(0, 0, 0, 0.7); } .g-img { background-size: contain; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; } .g-img-blur { position: relative; overflow: hidden; margin: 0 auto; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -2; width: 100vw; height: 100vh; } .g-img-blur::after { -webkit-filter: blur(40px); -moz-filter: blur(40px); -ms-filter: blur(40px); filter: blur(40px); content: ''; position: absolute; top: 0; right: 0; bottom: 0; left: 0; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -1; height: 120vh; width: 120vw; background-image: url('img/IMG_20190518_113836.jpg'); } .g-img1 { background-image: url('img/IMG_20190518_113836.jpg'); } .g-img12 { background-image: url('img/IMG_20190518_113836.jpg'); } .g-img2 { background-image: url('img/mmexport1560563302307.jpg'); } .g-img3 { background-image: url('img/faceu_8004457_20190518191640.jpg'); } .g-img4 { background-image: url('img/faceu_0_20190607123059.jpg'); } .g-img5 { background-image: url('img/faceu_8004457_20190518185413.jpg'); } .g-img6 { background-image: url('img/mmexport1560563312297.jpg'); } .g-img7 { background-image: url('img/mmexport1560563316561.jpg'); } .g-img-blur1 { position: relative; overflow: hidden; margin: 0 auto; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -2; width: 100vw; height: 100vh; } .g-img-blur1::after { -webkit-filter: blur(40px); -moz-filter: blur(40px); -ms-filter: blur(40px); filter: blur(40px); content: ''; position: absolute; top: 0; right: 0; bottom: 0; left: 0; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -1; height: 120vh; width: 120vw; background-image: url('img/IMG_20190518_113836.jpg'); } .g-img-blur2 { position: relative; overflow: hidden; margin: 0 auto; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -2; width: 100vw; height: 100vh; } .g-img-blur2::after { -webkit-filter: blur(40px); -moz-filter: blur(40px); -ms-filter: blur(40px); filter: blur(40px); content: ''; position: absolute; top: 0; right: 0; bottom: 0; left: 0; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -1; height: 120vh; width: 120vw; background-image: url('img/IMG_20190518_113836.jpg'); } .g-img-blur3 { position: relative; overflow: hidden; margin: 0 auto; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -2; width: 100vw; height: 100vh; } .g-img-blur3::after { -webkit-filter: blur(40px); -moz-filter: blur(40px); -ms-filter: blur(40px); filter: blur(40px); content: ''; position: absolute; top: 0; right: 0; bottom: 0; left: 0; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -1; height: 120vh; width: 120vw; background-image: url('img/IMG_20190518_113836.jpg'); } .g-img-blur4 { position: relative; overflow: hidden; margin: 0 auto; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -2; width: 100vw; height: 100vh; } .g-img-blur4::after { -webkit-filter: blur(40px); -moz-filter: blur(40px); -ms-filter: blur(40px); filter: blur(40px); content: ''; position: absolute; top: 0; right: 0; bottom: 0; left: 0; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -1; height: 120vh; width: 120vw; background-image: url('img/IMG_20190518_113836.jpg'); } .g-img-blur5 { position: relative; overflow: hidden; margin: 0 auto; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -2; width: 100vw; height: 100vh; } .g-img-blur5::after { -webkit-filter: blur(40px); -moz-filter: blur(40px); -ms-filter: blur(40px); filter: blur(40px); content: ''; position: absolute; top: 0; right: 0; bottom: 0; left: 0; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -1; height: 120vh; width: 120vw; background-image: url('img/IMG_20190518_113836.jpg'); } .g-img-blur6 { position: relative; overflow: hidden; margin: 0 auto; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -2; width: 100vw; height: 100vh; } .g-img-blur6::after { -webkit-filter: blur(40px); -moz-filter: blur(40px); -ms-filter: blur(40px); filter: blur(40px); content: ''; position: absolute; top: 0; right: 0; bottom: 0; left: 0; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -1; height: 120vh; width: 120vw; background-image: url('img/IMG_20190518_113836.jpg'); } .g-img-blur7 { position: relative; overflow: hidden; margin: 0 auto; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -2; width: 100vw; height: 100vh; } .g-img-blur7::after { -webkit-filter: blur(40px); -moz-filter: blur(40px); -ms-filter: blur(40px); filter: blur(40px); content: ''; position: absolute; top: 0; right: 0; bottom: 0; left: 0; background-size: cover; background-repeat: no-repeat; background-position: center center; background-attachment: fixed; z-index: -1; height: 120vh; width: 120vw; background-image: url('img/IMG_20190518_113836.jpg'); }"},{"title":"简历","date":"2020-02-20T15:03:54.000Z","url":"/private/cv.html","categories":[[" ",""]],"content":"个人信息 张丁元 / 男 / 1996 工作年限: 3年 技术博客:  Github:  联系方式 手机: 17607195053 邮箱: &#106;&#117;&#x73;&#x74;&#102;&#x6f;&#x72;&#108;&#x78;&#122;&#64;&#103;&#109;&#x61;&#x69;&#x6c;&#46;&#99;&#111;&#109; 工作经历统信科技有限公司 (原 武汉深之度科技有限公司) (2016/09 —— 至今)武汉地区技术委员会 (2020/07 – 至今)职位描述: 为了提高研发中心技术能力，保持研发中心的技术创造性，保证技术决策的合理性，满足产品发展趋势，提供前瞻性的解决方案。 工作性质: 参与制定研发中心的年度技术规划 参加相关项目的关键技术论证，技术评审 对关键的项目，产品提供提供技术调研、评审，提供技术咨询服务和改进意见 对公司内部技术人才培养提供建议 对技术专利提供规划，对技术资源进行沉淀 武汉地区开发部桌面组技术小组 (2020/05 – 至今)职位描述: 负责部门整体技术的架构，新技术领域的探索，技术性知识输出，为部门各个方面提供技术后盾。 工作性质: 制定开发框架，优化项目代码，编写调研报告等。 deepin-recovery (2020/01 – 2020/05)项目简介: 提供Linux Deepin发行版分区级别的备份还原方案。 项目描述: 项目包含恢复出厂设置、手动备份、手动还原等功能。 工作性质: 项目负责人，负责架构设计和功能开发，项目功能横跨三个不同的项目，通过约定配置文件充当接口约束，并通过封装Task类来解析任务数据，简化封装流程。现在带领3人团队开发和维护备份还原项目，涵盖dde-control-center、live-filesystem项目。 deepin-installer (2018/08 – 2020/05)项目简介: 提供Linux Deepin发行版的安装功能。 项目描述: 项目包含用户信息、时区、组件化列表、分区、语言选择等功能。 工作性质: 项目负责人，期间维护项目代码和新功能开发。对项目进行过多次重构，使用智能指针解决内存泄漏问题、使用继承的方式合并不同类型的分区代码、使用接口的方式实现了新的页面框架，简化页面调度和疏通页面流程，并优化了OEM定制时配置文件的合并方案。现在带领5人团队开发LVM分区方案、无人值守安装和字符界面安装等。 dde-session-ui (2017/03 – 2018/07)地址:  项目简介: DDE桌面环境的用户会话相关的界面，例如锁屏，登录界面等。 项目描述: 项目包含用户锁屏及用户登录程序，还有和会话提醒相关的窗管选择器、内存不足对话框、用户OSD显示等程序。 工作性质: 项目负责人，负责维护代码，期间对项目进行了两次重构，第一次架构重构，对项目代码进行解耦，消除了大量重复代码，扩展了可维护性。第二次重构是拆分无关二进制，并使用CMake构建系统，统一公司内部的编译系统。 dde-dock (2017/05 – 2019/05)地址:  项目简介: DDE桌面环境的任务栏，为桌面环境提供当前执行程序的切换及托盘功能。 项目描述: 项目包含启动器图标、应用管理、托盘管理和插件系统功能。 工作性质: 项目负责人，负责维护和优化，通过调整框架加载顺序和重写插件调度实现插件的快速加载，不会造成主界面的卡顿。通过特殊的操作方式优化启动动画，使程序启动时画面更加友好。 dde-launcher (2017/05 – 2019/05)地址:  项目简介: DDE桌面环境的应用启动器，为桌面环境提供应用列表。 项目描述: 项目包含全屏模式、mini模式、分类管理功能。 工作性质: 项目负责人，负责维护和优化项目，通过增加缓存的方式来提升程序启动和运行速度，在国产处理器平台上进行过内存占用优化。 dde-control-center (2016/09 – 2019/6)地址:  项目简介: DDE桌面环境的控制中心，负责管理系统及个人用户的设置。 项目描述: 项目包含账户管理、显示管理、键盘及鼠标管理、用户个性化等功能。 工作性质: 负责项目的架构，开发与维护。进行组员代码 review，性能分析，架构调整等方面的工作 开源项目及作品deepin-topbar地址:  项目描述: 使用Qt和C++在dde桌面实现类似于MacOS的顶栏，扩展了系统操作，可以用来访问网络，控制系统音量。通过调用X11的接口实现对屏幕显示区域的划分，通过设置窗口属性实现阴影和本地在桌面的层叠关系。 项目采用模块化开发，每个功能都是独立的，通过定义接口类来实现框架和模块之间的访问与控制。 deepin-dreamscene地址  项目描述 使用Qt和C++在dde桌面实现了windows下Wallpaper Engine软件的动态视频壁纸软件。通过调用X11的接口将程序置于最底层，并调用mpv库实现视频播放。 技能清单以下是我熟练使用的技能： 操作系统: Linux 编程语言: C++、Qt 开发工具: QtCreator/Visual Studio Code 构建系统: CMake/QMake 管理系统: Git 自我总结我这几年主攻方向是C++/Qt，项目中使用标准库和Qt提供的智能指针来避免内存泄漏，使用迭代器避免出现内存异常，使用设计模式来完善项目架构，通过QFuture和std::thread避免阻塞UI线程。在公司负责多个项目团队的技术架构及技术指导，并对团队的技术栈进行定期培训，对代码进行审核和优化。现在就任武汉开发部桌面组技术小组。 致谢感谢您花时间阅读我的简历, 期待能有机会和您共事."},{"date":"2021-03-04T07:40:49.481Z","url":"/search/index.html","categories":[[" ",""]]},{"title":"Tags","date":"2021-03-04T07:40:49.481Z","url":"/tags/index.html","categories":[[" ",""]]}]